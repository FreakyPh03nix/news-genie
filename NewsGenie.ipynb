{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eed16946"
      },
      "source": [
        "## Implement solution\n",
        "\n",
        "### Subtask:\n",
        "Write code based on the instructions.\n",
        "1. Handles conversations: Develop an AI chatbot that can interpret and answer general  queries while distinguishing them from news requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabee996"
      },
      "source": [
        "##**Subtask**:\n",
        "Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/requirements.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PJ_n5RSOcz4",
        "outputId": "f929eb35-2799-4dd5-f111-aac5283fdfc8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 1)) (0.3.27)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 2)) (1.51.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 3)) (2.32.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 4)) (4.13.5)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 5)) (0.3.31)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.12/dist-packages (from -r /content/requirements.txt (line 6)) (0.7.13)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/requirements.txt (line 1)) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/requirements.txt (line 1)) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/requirements.txt (line 1)) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/requirements.txt (line 1)) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/requirements.txt (line 1)) (2.0.44)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit->-r /content/requirements.txt (line 2)) (6.5.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r /content/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r /content/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r /content/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r /content/requirements.txt (line 3)) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/requirements.txt (line 4)) (2.8)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/requirements.txt (line 5)) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/requirements.txt (line 5)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/requirements.txt (line 5)) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/requirements.txt (line 5)) (0.4.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python->-r /content/requirements.txt (line 6)) (0.12.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python->-r /content/requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/requirements.txt (line 5)) (1.22.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (2.11.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r /content/requirements.txt (line 5)) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r /content/requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/requirements.txt (line 2)) (4.0.12)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain->-r /content/requirements.txt (line 1)) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r /content/requirements.txt (line 1)) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r /content/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->-r /content/requirements.txt (line 1)) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python->-r /content/requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python->-r /content/requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python->-r /content/requirements.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit->-r /content/requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit->-r /content/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit->-r /content/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r /content/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r /content/requirements.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r /content/requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->-r /content/requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r /content/requirements.txt (line 1)) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python->-r /content/requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/requirements.txt (line 2)) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain->-r /content/requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit->-r /content/requirements.txt (line 2)) (0.28.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit->-r /content/requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r /content/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python->-r /content/requirements.txt (line 6)) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN95pNC5OWSS"
      },
      "source": [
        "##**Subtask**:\n",
        "Choose tokenizer\n",
        "###NLTK\n",
        "To fully set up the NLTK environment for text processing, I need to download the 'punkt' and 'punkt_tab' tokenizer data. This ensures the environment is ready for subsequent NLP tasks.\n",
        "\n",
        "##OR\n",
        "\n",
        "###spaCy\n",
        "Alternate Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d39eac00",
        "outputId": "abf9fd74-baa2-42d9-deb3-cedf043bb0e7"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time # Import time for delays\n",
        "##import spacy? alt tokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "print(\"'punkt' tokenizer data downloaded successfully.\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'punkt' tokenizer data downloaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cb51f8"
      },
      "source": [
        "##Subtask:\n",
        "creat a function to tokenize the user input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c35b14f4",
        "outputId": "fcb7df9c-5aac-4db9-f4c5-27e3f0385973"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tokenizes and normalizes the input text.\n",
        "    Converts to lowercase and removes punctuation (for simplicity).\n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove non-alphabetic tokens\n",
        "    normalized_tokens = [word for word in tokens if word.isalpha()]\n",
        "    return normalized_tokens\n",
        "\n",
        "print(\"Helper function 'preprocess_text' defined successfully.\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper function 'preprocess_text' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test:\n",
        "preprocess_text"
      ],
      "metadata": {
        "id": "peTlbCQDo82A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases for preprocess_text function\n",
        "\n",
        "print(\"--- Testing preprocess_text function ---\")\n",
        "\n",
        "# Test 1: Standard sentence with punctuation and mixed case\n",
        "input_text_1 = \"Hello, World! This is a Test sentence.\"\n",
        "processed_1 = preprocess_text(input_text_1)\n",
        "print(f\"Input: '{input_text_1}'\")\n",
        "print(f\"Processed: {processed_1}\\n\")\n",
        "\n",
        "# Test 2: Sentence with numbers and special characters\n",
        "input_text_2 = \"Buy 10 apples for $2.50!\"\n",
        "processed_2 = preprocess_text(input_text_2)\n",
        "print(f\"Input: '{input_text_2}'\")\n",
        "print(f\"Processed: {processed_2}\\n\")\n",
        "\n",
        "# Test 3: Empty string\n",
        "input_text_3 = \"\"\n",
        "processed_3 = preprocess_text(input_text_3)\n",
        "print(f\"Input: '{input_text_3}'\")\n",
        "print(f\"Processed: {processed_3}\\n\")\n",
        "\n",
        "# Test 4: String with only punctuation and numbers\n",
        "input_text_4 = \"!@#$%^&*()12345\"\n",
        "processed_4 = preprocess_text(input_text_4)\n",
        "print(f\"Input: '{input_text_4}'\")\n",
        "print(f\"Processed: {processed_4}\\n\")\n",
        "\n",
        "# Test 5: Sentence with contractions (should be split and non-alphabetic removed)\n",
        "input_text_5 = \"I don't know, can't you tell?\"\n",
        "processed_5 = preprocess_text(input_text_5)\n",
        "print(f\"Input: '{input_text_5}'\")\n",
        "print(f\"Processed: {processed_5}\\n\")\n",
        "\n",
        "# Test 6: Text with leading/trailing spaces\n",
        "input_text_6 = \"  Some text with spaces  \"\n",
        "processed_6 = preprocess_text(input_text_6)\n",
        "print(f\"Input: '{input_text_6}'\")\n",
        "print(f\"Processed: {processed_6}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QP_s596pFTN",
        "outputId": "ac25e043-0bc0-4185-fb0f-a38f2fa398dd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing preprocess_text function ---\n",
            "Input: 'Hello, World! This is a Test sentence.'\n",
            "Processed: ['hello', 'world', 'this', 'is', 'a', 'test', 'sentence']\n",
            "\n",
            "Input: 'Buy 10 apples for $2.50!'\n",
            "Processed: ['buy', 'apples', 'for']\n",
            "\n",
            "Input: ''\n",
            "Processed: []\n",
            "\n",
            "Input: '!@#$%^&*()12345'\n",
            "Processed: []\n",
            "\n",
            "Input: 'I don't know, can't you tell?'\n",
            "Processed: ['i', 'do', 'know', 'ca', 'you', 'tell']\n",
            "\n",
            "Input: '  Some text with spaces  '\n",
            "Processed: ['some', 'text', 'with', 'spaces']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cee0d31"
      },
      "source": [
        "## Subtask:\n",
        "Define a function that categorizes queries into news or general"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14bb95d4",
        "outputId": "595405d9-7a40-403b-cde0-ff560ffc8400"
      },
      "source": [
        "def recognize_intent(user_input):\n",
        "    \"\"\"\n",
        "    Analyzes user input to classify the intent as either 'general_query' or 'news_request'.\n",
        "    \"\"\"\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    lower_user_input = user_input.lower()\n",
        "\n",
        "    # Define single-word news keywords\n",
        "    news_single_keywords = [\"news\", \"headlines\"]\n",
        "\n",
        "    # Define multi-word news phrases based on the Chatbot Scope and Requirements Definition\n",
        "    # and observations from previous testing\n",
        "    news_phrases_to_match = [\n",
        "        \"latest updates\", \"current events\", \"breaking news\", \"today's news\",\n",
        "        \"recent developments\", \"what's happening\", \"tell me the news\",\n",
        "        \"give me today's headlines\", \"what are the latest stories\",\n",
        "        \"what is happening in the world\"\n",
        "    ]\n",
        "\n",
        "    # Check for single-word keyword matches in processed tokens\n",
        "    for token in processed_input:\n",
        "        if token in news_single_keywords:\n",
        "            return \"news_request\"\n",
        "\n",
        "    # Check for multi-word phrase matches in the original lowercased input\n",
        "    for phrase in news_phrases_to_match:\n",
        "        if phrase in lower_user_input:\n",
        "            return \"news_request\"\n",
        "\n",
        "    return \"general_query\"\n",
        "\n",
        "print(\"Intent recognition function 'recognize_intent' defined successfully.\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent recognition function 'recognize_intent' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test:\n",
        "recognize_intent"
      ],
      "metadata": {
        "id": "W_ER9C8cpT1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases for recognize_intent function\n",
        "\n",
        "print(\"--- Testing recognize_intent function ---\")\n",
        "\n",
        "# Test 1: Clear general query\n",
        "input_ri_1 = \"What is the capital of Japan?\"\n",
        "intent_ri_1 = recognize_intent(input_ri_1)\n",
        "print(f\"Input: '{input_ri_1}' -> Intent: {intent_ri_1}\")\n",
        "\n",
        "# Test 2: Clear news request (single keyword)\n",
        "input_ri_2 = \"Tell me the news.\"\n",
        "intent_ri_2 = recognize_intent(input_ri_2)\n",
        "print(f\"Input: '{input_ri_2}' -> Intent: {intent_ri_2}\")\n",
        "\n",
        "# Test 3: Clear news request (phrase)\n",
        "input_ri_3 = \"What are the latest updates on space exploration?\"\n",
        "intent_ri_3 = recognize_intent(input_ri_3)\n",
        "print(f\"Input: '{input_ri_3}' -> Intent: {intent_ri_3}\")\n",
        "\n",
        "# Test 4: General query with some news-like words but not a news request\n",
        "input_ri_4 = \"What's the meaning of current?\"\n",
        "intent_ri_4 = recognize_intent(input_ri_4)\n",
        "print(f\"Input: '{input_ri_4}' -> Intent: {intent_ri_4}\")\n",
        "\n",
        "# Test 5: News request with a keyword in the middle\n",
        "input_ri_5 = \"I want to know about recent developments in AI.\"\n",
        "intent_ri_5 = recognize_intent(input_ri_5)\n",
        "print(f\"Input: '{input_ri_5}' -> Intent: {intent_ri_5}\")\n",
        "\n",
        "# Test 6: Mixed query, should lean towards news if news phrases are strong\n",
        "input_ri_6 = \"Can you give me today's headlines and also tell me about dogs?\"\n",
        "intent_ri_6 = recognize_intent(input_ri_6)\n",
        "print(f\"Input: '{input_ri_6}' -> Intent: {intent_ri_6}\")\n",
        "\n",
        "# Test 7: Query with only a single news keyword\n",
        "input_ri_7 = \"headlines\"\n",
        "intent_ri_7 = recognize_intent(input_ri_7)\n",
        "print(f\"Input: '{input_ri_7}' -> Intent: {intent_ri_7}\")\n",
        "\n",
        "# Test 8: General knowledge question\n",
        "input_ri_8 = \"Who painted the Mona Lisa?\"\n",
        "intent_ri_8 = recognize_intent(input_ri_8)\n",
        "print(f\"Input: '{input_ri_8}' -> Intent: {intent_ri_8}\")\n",
        "\n",
        "# Test 9: More complex news request phrase\n",
        "input_ri_9 = \"What is happening in the world right now?\"\n",
        "intent_ri_9 = recognize_intent(input_ri_9)\n",
        "print(f\"Input: '{input_ri_9}' -> Intent: {intent_ri_9}\")\n",
        "\n",
        "# Test 10: General query that might contain common words found in news but isn't news\n",
        "input_ri_10 = \"Tell me about historical events.\"\n",
        "intent_ri_10 = recognize_intent(input_ri_10)\n",
        "print(f\"Input: '{input_ri_10}' -> Intent: {intent_ri_10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsFPRli3pZ1v",
        "outputId": "d8d0d19e-3888-4f01-d03a-104cdfbe152a"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing recognize_intent function ---\n",
            "Input: 'What is the capital of Japan?' -> Intent: general_query\n",
            "Input: 'Tell me the news.' -> Intent: news_request\n",
            "Input: 'What are the latest updates on space exploration?' -> Intent: news_request\n",
            "Input: 'What's the meaning of current?' -> Intent: general_query\n",
            "Input: 'I want to know about recent developments in AI.' -> Intent: news_request\n",
            "Input: 'Can you give me today's headlines and also tell me about dogs?' -> Intent: news_request\n",
            "Input: 'headlines' -> Intent: news_request\n",
            "Input: 'Who painted the Mona Lisa?' -> Intent: general_query\n",
            "Input: 'What is happening in the world right now?' -> Intent: news_request\n",
            "Input: 'Tell me about historical events.' -> Intent: general_query\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bff70df"
      },
      "source": [
        "## Subtask:\n",
        "select news search and general search apis to use and set them up\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import time\n",
        "from google.colab import userdata\n",
        "from tavily import TavilyClient\n",
        "\n",
        "# Get secrets from Colab userdata\n",
        "NEWS_API_KEY = userdata.get('GNEWS_API_KEY')\n",
        "print(NEWS_API_KEY)\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# For NewsAPI: NEWS_API_BASE_URL = \"https://newsapi.org/v2/everything\"\n",
        "# For GNews API: NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "\n",
        "# Initialize the Tavily client with the API key\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V92cOZsYdcNw",
        "outputId": "c2278d56-351c-4038-b38b-6e1e03a3013b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "effcca425122f0945d1d453b3dec4bd2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9afd9ce3"
      },
      "source": [
        "##Subtask:\n",
        "define fetch news function to retrieve the news related to a query\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c380e2",
        "outputId": "f12405e1-b4bb-4b62-f5f0-d9333e069cfc"
      },
      "source": [
        "\n",
        "def fetch_news(query):\n",
        "    \"\"\"\n",
        "    Fetches news articles from a news API based on the query.\n",
        "    \"\"\"\n",
        "    if not NEWS_API_KEY:\n",
        "        return \"News API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    if not NEWS_API_BASE_URL:\n",
        "        return \"News API base URL is not set. Please provide a valid URL.\"\n",
        "\n",
        "    try:\n",
        "        params = {\n",
        "            'q': query,\n",
        "            'lang': 'en',\n",
        "            'country': 'us', # Or other relevant country codes\n",
        "            'max': 5, # Number of articles to fetch\n",
        "            'apikey': NEWS_API_KEY\n",
        "        }\n",
        "        response = requests.get(NEWS_API_BASE_URL, params=params)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors\n",
        "        data = response.json()\n",
        "\n",
        "        articles = data.get('articles', [])\n",
        "        if not articles:\n",
        "            return \"Sorry, I couldn't find any news for that query.\"\n",
        "\n",
        "        news_output = []\n",
        "        for i, article in enumerate(articles):\n",
        "            title = article.get('title', 'No Title')\n",
        "            description = article.get('description', 'No Description')\n",
        "            url = article.get('url', '#')\n",
        "            news_output.append(f\"{i+1}. {title}\\n   {description}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(news_output)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching news: {e}\"\n",
        "    except ValueError as e:\n",
        "        return f\"Error parsing API response: {e}\"\n",
        "\n",
        "print(\"News fetching function 'fetch_news' defined successfully.\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News fetching function 'fetch_news' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef94f69e"
      },
      "source": [
        "### Tests `fetch_news` function\n",
        "\n",
        "tests of function that fetches the related news question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86546e2e",
        "outputId": "98637a25-4d4e-479a-a224-bddb30d300b2"
      },
      "source": [
        "# Test cases for fetch_news function\n",
        "\n",
        "print(\"--- Testing fetch_news function ---\")\n",
        "\n",
        "# Test 1: Valid news query\n",
        "news_query_1 = \"technology news\"\n",
        "print(f\"\\nNews Query: '{news_query_1}'\")\n",
        "news_response_1 = fetch_news(news_query_1)\n",
        "print(f\"News Response:\\n{news_response_1}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 2: Another valid news query\n",
        "news_query_2 = \"climate change updates\"\n",
        "print(f\"\\nNews Query: '{news_query_2}'\")\n",
        "news_response_2 = fetch_news(news_query_2)\n",
        "print(f\"News Response:\\n{news_response_2}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 3: Query for which no news might be found\n",
        "news_query_3 = \"nonexistent topic news 12345\"\n",
        "print(f\"\\nNews Query: '{news_query_3}'\")\n",
        "news_response_3 = fetch_news(news_query_3)\n",
        "print(f\"News Response:\\n{news_response_3}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 4: Query with a slightly different phrasing\n",
        "news_query_4 = \"latest economic news\"\n",
        "print(f\"\\nNews Query: '{news_query_4}'\")\n",
        "news_response_4 = fetch_news(news_query_4)\n",
        "print(f\"News Response:\\n{news_response_4}\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing fetch_news function ---\n",
            "\n",
            "News Query: 'technology news'\n",
            "News Response:\n",
            "1. Google to invest $40 billion in new data centers in Texas, Bloomberg News reports\n",
            "   Alphabet's Google plans to invest $40 billion in three new data centers in Texas, Bloomberg News reported on Friday, as the technology giant accelerates efforts to expand capacity to support its artificial intelligence ambitions.\n",
            "   Read more: https://www.reuters.com/business/google-invest-40-billion-new-data-centers-texas-bloomberg-news-reports-2025-11-14/\n",
            "\n",
            "2. Fox News AI Newsletter: Russian robot faceplants in humiliating debut\n",
            "   Stay informed on the latest AI technology advancements, industry breakthroughs, and the challenges shaping our future — including highlights like Russia’s robot’s humiliating debut and more.\n",
            "   Read more: https://www.foxnews.com/tech/ai-newsletter-russian-robot-faceplants-humiliating-debut\n",
            "\n",
            "3. Top Tech News Today, November 14, 2025\n",
            "   Top Tech News Stories Today — Your Quick Briefing on the Latest Technology News, Global Innovation, and AI-Driven Shifts Reshaping the Future It’s Friday, November 14, 2025, and we’re back with your in-depth look at the most important tech stories shaping today’s world — from next-generation AI research tools and breakthrough data-center infrastructure to Big\n",
            "   Read more: https://techstartups.com/2025/11/14/top-tech-news-today-november-14-2025/\n",
            "\n",
            "4. Sealy mattress deals news: Save $800 during Wayfair's Early Black Friday sale today\n",
            "   Premium memory foam mattresses with CopperChill Technology now available for just $389, down from $1,199 for a limited time.\n",
            "   Read more: https://www.pennlive.com/shopping-deals/2025/11/this-luxurious-sealy-memory-foam-mattress-is-now-800-cheaper-at-wayfairs-early-black-friday-sale.html\n",
            "\n",
            "5. Top Tech News Today, November 13, 2025\n",
            "   Top Tech News Stories Today — Your Quick Briefing on the Latest Technology News, Global Innovation, and AI-Driven Shifts Reshaping the Future It’s Thursday, November 13, 2025, and we’re back with your in-depth look at the most important tech stories shaping today’s world — from breakthrough AI infrastructure and Big Tech strategy pivots to quantum\n",
            "   Read more: https://techstartups.com/2025/11/13/top-tech-news-today-november-13-2025/\n",
            "\n",
            "\n",
            "News Query: 'climate change updates'\n",
            "News Response:\n",
            "Sorry, I couldn't find any news for that query.\n",
            "\n",
            "News Query: 'nonexistent topic news 12345'\n",
            "News Response:\n",
            "Sorry, I couldn't find any news for that query.\n",
            "\n",
            "News Query: 'latest economic news'\n",
            "News Response:\n",
            "1. Tariff Relief In The Works To Cut Grocery Bills\n",
            "   Get the latest on Wall Street trends, market analysis, and global economic updates in this concise news roundup.\n",
            "   Read more: https://seekingalpha.com/article/4843752-tariff-relief-in-the-works-to-cut-grocery-bills\n",
            "\n",
            "2. How Well Will Russia Withstand New U.S. Sanctions?\n",
            "   Get the latest stock market updates, economic news, and analyses.\n",
            "   Read more: https://seekingalpha.com/article/4832965-how-well-will-russia-withstand-new-u-s-sanctions\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6e5f201"
      },
      "source": [
        "##Subtask:\n",
        "define handle news request function to prep query and pass it to news request function fetch_news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd6a479f",
        "outputId": "6cd42c6f-99fc-45ca-ba27-df2582392c15"
      },
      "source": [
        "import re\n",
        "\n",
        "def handle_news_request(user_input):\n",
        "    \"\"\"\n",
        "    Handles a news-specific request by extracting keywords from the user input\n",
        "    and fetching relevant news articles.\n",
        "    \"\"\"\n",
        "    # Define phrases that indicate a news request but should be removed from the query\n",
        "    news_request_phrases = [\n",
        "        \"tell me the news about\",\n",
        "        \"give me today's headlines about\",\n",
        "        \"what are the latest stories on\",\n",
        "        \"what are the latest updates on\",\n",
        "        \"latest news on\",\n",
        "        \"news about\",\n",
        "        \"headlines about\",\n",
        "        \"current events about\",\n",
        "        \"breaking news about\",\n",
        "        \"today's news on\",\n",
        "        \"recent developments on\",\n",
        "        \"what's happening with\",\n",
        "        \"tell me the news\",\n",
        "        \"give me today's headlines\",\n",
        "        \"what are the latest stories\",\n",
        "        \"what is happening in the world\",\n",
        "        \"news\",\n",
        "        \"headlines\",\n",
        "        \"latest updates\",\n",
        "        \"current events\",\n",
        "        \"breaking news\",\n",
        "        \"today's news\",\n",
        "        \"recent developments\",\n",
        "        \"what's happening\"\n",
        "    ]\n",
        "\n",
        "    query = user_input.lower()\n",
        "\n",
        "    # Remove news request phrases from the query\n",
        "    for phrase in news_request_phrases:\n",
        "        if phrase in query:\n",
        "            query = query.replace(phrase, \"\").strip()\n",
        "\n",
        "    # Further clean the query by removing punctuation (except spaces) and extra spaces\n",
        "    query = re.sub(r'[^a-zA-Z0-9\\s]', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "\n",
        "    # If the query becomes empty after removing phrases and cleaning, set a default\n",
        "    if not query:\n",
        "        query = \"top stories\"\n",
        "\n",
        "    return fetch_news(query)\n",
        "\n",
        "print(\"News request handler function 'handle_news_request' defined successfully.\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News request handler function 'handle_news_request' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test\n",
        "handle_news_request"
      ],
      "metadata": {
        "id": "WXIqO8ZJnQ-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases for handle_news_request function\n",
        "\n",
        "print(\"\\n--- Testing handle_news_request function ---\")\n",
        "\n",
        "# Test 1: Clear news query\n",
        "user_input_hr_1 = \"latest news on science\"\n",
        "print(f\"\\nInput: '{user_input_hr_1}'\")\n",
        "response_hr_1 = handle_news_request(user_input_hr_1)\n",
        "print(f\"Response:\\n{response_hr_1}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 2: News query with a less specific news phrase\n",
        "user_input_hr_2 = \"what's happening in politics?\"\n",
        "print(f\"\\nInput: '{user_input_hr_2}'\")\n",
        "response_hr_2 = handle_news_request(user_input_hr_2)\n",
        "print(f\"Response:\\n{response_hr_2}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 3: Query that should default to 'top stories'\n",
        "user_input_hr_3 = \"news\"\n",
        "print(f\"\\nInput: '{user_input_hr_3}'\")\n",
        "response_hr_3 = handle_news_request(user_input_hr_3)\n",
        "print(f\"Response:\\n{response_hr_3}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 4: Query with redundant news phrases and punctuation\n",
        "user_input_hr_4 = \"Tell me the breaking news about the global economy!\"\n",
        "print(f\"\\nInput: '{user_input_hr_4}'\")\n",
        "response_hr_4 = handle_news_request(user_input_hr_4)\n",
        "print(f\"Response:\\n{response_hr_4}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 5: Query with only news phrases, expecting default query\n",
        "user_input_hr_5 = \"today's headlines\"\n",
        "print(f\"\\nInput: '{user_input_hr_5}'\")\n",
        "response_hr_5 = handle_news_request(user_input_hr_5)\n",
        "print(f\"Response:\\n{response_hr_5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O26aRjcLoQUy",
        "outputId": "ae6b37f6-44cc-43b1-f0da-ecb0792777aa"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing handle_news_request function ---\n",
            "\n",
            "Input: 'latest news on science'\n",
            "Response:\n",
            "1. Dr. Oz to Newsmax: MAHA Movement 'Radically Transparent'\n",
            "   On President Donald Trump's 300th day in the White House, Dr. Mehmet Oz told Newsmax the MAHA movement's commitment to radical transparency is restoring trust in science.\n",
            "   Read more: https://www.newsmax.com/newsmax-tv/mehmet-oz-newsmax-maha/2025/11/14/id/1234659/\n",
            "\n",
            "2. Museum of Science and Industry workers set strike date as contract talks continue\n",
            "   The strike date comes ahead of a scheduled bargaining session on Nov. 17, the final meeting before the deadline.\n",
            "   Read more: https://chicago.suntimes.com/news/2025/11/14/museum-science-industry-workers-strike-date-contract-talks-labor\n",
            "\n",
            "3. Brick Planet Brings LEGO Wonders to DMNS\n",
            "   The massive LEGO art installation by Sean Kenney will be on display at the Denver Museum of Nature & Science through May 3.\n",
            "   Read more: https://www.westword.com/arts-culture/brick-planet-brings-lego-wonders-to-the-denver-museum-of-nature-science-40805159/\n",
            "\n",
            "4. Andy Richter Says Zepbound and 'DWTS' Helped Him with 'Physical Transformation'\n",
            "   Andy Richter says he took Zepound to lose weight and says he doesn't \"have any qualms about using science\" to get the help he needs.\n",
            "   Read more: https://people.com/andy-richter-dwts-zepbound-weight-loss-11849747\n",
            "\n",
            "5. COC students launch high-altitude science project\n",
            "   News release   The College of the Canyons Society of Physics and Engineering Students successfully launched a high-altitude balloon carrying a scientific payload that members designed, built, and tested over several […]\n",
            "   Read more: https://signalscv.com/2025/11/coc-students-launch-high-altitude-science-project/\n",
            "\n",
            "\n",
            "Input: 'what's happening in politics?'\n",
            "Response:\n",
            "1. Japan Urges China to Take Steps After It Discouraged Visits to Japan, Kyodo Reports\n",
            "   US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, and find news you can use in politics, business, health, and education.\n",
            "   Read more: https://www.usnews.com/news/world/articles/2025-11-15/japan-urges-china-to-take-steps-after-it-discouraged-visits-to-japan-kyodo-reports\n",
            "\n",
            "2. Dear Annie: A lifelong friend cut ties because of the candidate I voted for\n",
            "   In today's Dear Annie column, Annie addresses politics and friendship.\n",
            "   Read more: https://www.cleveland.com/advice/2025/11/dear-annie-a-lifelong-friend-cut-ties-because-of-the-candidate-i-voted-for.html\n",
            "\n",
            "3. US Jury Says Apple Must Pay Masimo $634 Million in Smartwatch Patent Case\n",
            "   US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, and find news you can use in politics, business, health, and education.\n",
            "   Read more: https://www.usnews.com/news/top-news/articles/2025-11-14/us-jury-says-apple-must-pay-masimo-634-million-in-smartwatch-patent-case\n",
            "\n",
            "4. US National Archives Releases Amelia Earhart Records Promised by Trump\n",
            "   US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, and find news you can use in politics, business, health, and education.\n",
            "   Read more: https://www.usnews.com/news/top-news/articles/2025-11-14/us-national-archives-releases-amelia-earhart-records-promised-by-trump\n",
            "\n",
            "5. Trump Officials Hold Meetings on Venezuela as Military Tensions Rise\n",
            "   US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, and find news you can use in politics, business, health, and education.\n",
            "   Read more: https://www.usnews.com/news/world/articles/2025-11-14/trump-officials-hold-meetings-on-venezuela-as-military-tensions-rise\n",
            "\n",
            "\n",
            "Input: 'news'\n",
            "Response:\n",
            "1. Top Startup and Tech Funding News Roundup - Week Ending November 14, 2025\n",
            "   It’s Friday, November 14, 2025, and we’re back with the top startup and tech funding news stories spanning the U.S. and global markets. From multi-billion-dollar AI coding platforms to nuclear energy, logistics, and legaltech, investors kept writing large checks across late stage, growth, and early institutional rounds. This week’s coverage spans Monday, November 10, through\n",
            "   Read more: https://techstartups.com/2025/11/14/top-startup-and-tech-funding-news-roundup-week-ending-november-14-2025/\n",
            "\n",
            "2. Stunt Legends Speak at Round Top Film Festival\n",
            "   From Cardboard Boxes to AI: Stunt Legends Share Stories, Wisdom at Round Top Film Festival\n",
            "   Read more: https://variety.com/2025/film/news/cardboard-boxes-ai-stunt-legends-round-top-film-festival-1236582410/\n",
            "\n",
            "3. Stunt Legends Speak at Round Top Film Festival\n",
            "   From Cardboard Boxes to AI: Stunt Legends Share Stories, Wisdom at Round Top Film Festival\n",
            "   Read more: https://variety.com/2025/film/festivals/cardboard-boxes-ai-stunt-legends-round-top-film-festival-1236582410/\n",
            "\n",
            "4. SFFILM’s Doc Stories Attracts Nonfiction Cinema’s Top Talents\n",
            "   SFFILM’s Doc Stories festival attracted many of the biggest names in nonfiction filmmaking, with an eye on impacting the Oscar race.\n",
            "   Read more: https://deadline.com/2025/11/doc-stories-anne-lai-jessie-fairbanks-interview-1236617261/\n",
            "\n",
            "5. Top Tech News Today, November 14, 2025\n",
            "   Top Tech News Stories Today — Your Quick Briefing on the Latest Technology News, Global Innovation, and AI-Driven Shifts Reshaping the Future It’s Friday, November 14, 2025, and we’re back with your in-depth look at the most important tech stories shaping today’s world — from next-generation AI research tools and breakthrough data-center infrastructure to Big\n",
            "   Read more: https://techstartups.com/2025/11/14/top-tech-news-today-november-14-2025/\n",
            "\n",
            "\n",
            "Input: 'Tell me the breaking news about the global economy!'\n",
            "Response:\n",
            "Sorry, I couldn't find any news for that query.\n",
            "\n",
            "Input: 'today's headlines'\n",
            "Response:\n",
            "1. Full Menus for 2025 Festival of the Holidays In Todays Daily Recap For 11/4/25\n",
            "   Full Menus for 2025 Festival of the Holidays In Todays Daily Recap For 11/4/25\n",
            "   Read more: https://wdwnt.com/2025/11/full-menus-for-2025-festival-of-the-holidays-daily-recap-11-4-25/\n",
            "\n",
            "2. Pure Hedge - Livestock and Grain\n",
            "   Grains About to Trade Higher - Cattle Markets Could be in Trouble + TODAYS FEEDER CATTLE TRADES + YESTERDAYS LIVE CATTLE TRADES\n",
            "   Read more: https://www.barchart.com/story/news/35900035/pure-hedge-livestock-and-grain\n",
            "\n",
            "3. Pure Hedge - Livestock and Grain\n",
            "   Grains About to Trade Higher - Cattle Markets Could be in Trouble + TODAYS FEEDER CATTLE TRADES + YESTERDAYS LIVE CATTLE TRADES\n",
            "   Read more: https://www.barchart.com/story/news/35900034/pure-hedge-livestock-and-grain\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "984fca34"
      },
      "source": [
        "## Subtask:\n",
        "create a similar function for general searches\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f990d1d7",
        "outputId": "b140d36c-1815-4e05-c7be-a5cc6bb0bfb4"
      },
      "source": [
        "def fetch_web_results(query):\n",
        "    \"\"\"\n",
        "    Fetches web search results using the Tavily API.\n",
        "    \"\"\"\n",
        "    if not TAVILY_API_KEY or TAVILY_API_KEY == \"YOUR_TAVILY_API_KEY_HERE\":\n",
        "        return \"Tavily API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    try:\n",
        "        response = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n",
        "\n",
        "        results = response.get('results', [])\n",
        "        if not results:\n",
        "            return \"Sorry, I couldn't find any relevant web results for that query using Tavily.\"\n",
        "\n",
        "        # Synthesize a main answer from the first result's content or a concise summary\n",
        "        # Tavily's response often includes a 'summary' field for the whole search\n",
        "        # Or we can pick the content from the first result\n",
        "\n",
        "        # Attempt to get a synthesized answer from the overall response if available\n",
        "        synthesized_answer = response.get('answer', 'No summary available.')\n",
        "\n",
        "        web_results_output = []\n",
        "        if synthesized_answer and synthesized_answer != 'No summary available.':\n",
        "            web_results_output.append(f\"Here's what I found: {synthesized_answer}\")\n",
        "        else:\n",
        "            # Fallback to the first result's content if no overall summary is provided\n",
        "            first_result_content = results[0].get('content', 'No content available.')\n",
        "            if first_result_content and len(first_result_content) > 100: # Take a snippet\n",
        "                web_results_output.append(f\"Here's a snippet from a top result: {first_result_content[:200]}...\")\n",
        "            elif first_result_content:\n",
        "                web_results_output.append(f\"Here's what I found: {first_result_content}\")\n",
        "            else:\n",
        "                web_results_output.append(\"Here are some top results:\")\n",
        "\n",
        "        web_results_output.append(\"Top results:\")\n",
        "\n",
        "        for i, item in enumerate(results):\n",
        "            title = item.get('title', 'No Title')\n",
        "            url = item.get('url', '#')\n",
        "            # Tavily 'content' can be long, so we take a snippet for description\n",
        "            content_snippet = item.get('content', 'No description available.')\n",
        "            if len(content_snippet) > 150:\n",
        "                content_snippet = content_snippet[:150] + '...'\n",
        "\n",
        "            web_results_output.append(f\"{i+1}. {title}\\n   {content_snippet}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(web_results_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching web results from Tavily: {e}\"\n",
        "\n",
        "print(\"Web search function 'fetch_web_results' defined successfully.\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Web search function 'fetch_web_results' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test:\n",
        "fetch_web_results"
      ],
      "metadata": {
        "id": "B8FU56tHpyT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases for fetch_web_results function\n",
        "\n",
        "print(\"--- Testing fetch_web_results function ---\")\n",
        "\n",
        "# Test 1: Standard factual query\n",
        "query_fwr_1 = \"What is the capital of Canada?\"\n",
        "print(f\"\\nQuery: '{query_fwr_1}'\")\n",
        "response_fwr_1 = fetch_web_results(query_fwr_1)\n",
        "print(f\"Response:\\n{response_fwr_1}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 2: Query for a specific event or topic\n",
        "query_fwr_2 = \"History of artificial intelligence\"\n",
        "print(f\"\\nQuery: '{query_fwr_2}'\")\n",
        "response_fwr_2 = fetch_web_results(query_fwr_2)\n",
        "print(f\"Response:\\n{response_fwr_2}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 3: Query with no expected results or very niche\n",
        "query_fwr_3 = \"Nonexistent mythical creature from obscure folklore\"\n",
        "print(f\"\\nQuery: '{query_fwr_3}'\")\n",
        "response_fwr_3 = fetch_web_results(query_fwr_3)\n",
        "print(f\"Response:\\n{response_fwr_3}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 4: A more complex question that requires synthesis\n",
        "query_fwr_4 = \"Explain quantum computing in simple terms.\"\n",
        "print(f\"\\nQuery: '{query_fwr_4}'\")\n",
        "response_fwr_4 = fetch_web_results(query_fwr_4)\n",
        "print(f\"Response:\\n{response_fwr_4}\")\n",
        "time.sleep(2) # Add delay to avoid rate limiting\n",
        "\n",
        "# Test 5: Query that should trigger the snippet fallback if no overall answer\n",
        "query_fwr_5 = \"Latest discoveries about dark matter\"\n",
        "print(f\"\\nQuery: '{query_fwr_5}'\")\n",
        "response_fwr_5 = fetch_web_results(query_fwr_5)\n",
        "print(f\"Response:\\n{response_fwr_5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTWwvdUGp2Jg",
        "outputId": "345d61e9-7427-4c11-c1c4-12dc6756fb93"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing fetch_web_results function ---\n",
            "\n",
            "Query: 'What is the capital of Canada?'\n",
            "Response:\n",
            "Here's a snippet from a top result: Ottawa is the capital city of Canada. It is located in the southern portion of the province of Ontario, at the confluence of the Ottawa River and the Rideau River. Ottawa borders Gatineau, Quebec, and...\n",
            "Top results:\n",
            "1. Ottawa - Wikipedia\n",
            "   Ottawa is the capital city of Canada. It is located in the southern portion of the province of Ontario, at the confluence of the Ottawa River and the ...\n",
            "   Read more: https://en.wikipedia.org/wiki/Ottawa\n",
            "\n",
            "2. The Capital Cities - Legislative Assembly of Ontario\n",
            "   Canada’s capital is also the second-largest city in Ontario with a regional population of close to 1.5 million people. Queen Victoria chose Ottawa as ...\n",
            "   Read more: https://www.ola.org/en/visit-learn/teach-learn-play/about-ontario/capital-cities\n",
            "\n",
            "3. Everything to Know about the Capital Cities of Canada\n",
            "   Ottawa is Canada's capital, named from an Algonquin word meaning 'trade.'\n",
            "   Each Canadian province and territory has its own capital city with unique...\n",
            "   Read more: https://www.thoughtco.com/capital-cities-of-canada-4173714\n",
            "\n",
            "4. Ottawa - Capital of Canada - Adventures.com\n",
            "   Ottawa is Canada’s capital city and has long been known as an important hub for commerce and travel. In fact, Ottawa’s name comes from the Algonquin w...\n",
            "   Read more: https://adventures.com/canada/attractions/cities-towns/ottawa/\n",
            "\n",
            "5. Canada - Wikipedia\n",
            "   densities, with the majority residing in its urban areas and large areas being sparsely populated. Canada's capital is Ottawa and its three largest me...\n",
            "   Read more: https://en.wikipedia.org/wiki/Canada\n",
            "\n",
            "\n",
            "Query: 'History of artificial intelligence'\n",
            "Response:\n",
            "Here's a snippet from a top result: The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic ...\n",
            "Top results:\n",
            "1. History of artificial intelligence - Wikipedia\n",
            "   The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or cons...\n",
            "   Read more: https://en.wikipedia.org/wiki/History_of_artificial_intelligence\n",
            "\n",
            "2. AI History: Key Milestones That Shaped Artificial Intelligence\n",
            "   From Alan Turing’s foundational questions to today’s breakthroughs in deep learning and generative AI, the history of artificial intelligence is one o...\n",
            "   Read more: https://www.grammarly.com/blog/ai/ai-history/\n",
            "\n",
            "3. What is the history of artificial intelligence (AI)? - Tableau\n",
            "   # What is the history of artificial intelligence (AI)?\n",
            "\n",
            "It may sometimes feel like AI is a recent development in technology. After all, it’s only beco...\n",
            "   Read more: https://www.tableau.com/data-insights/ai/history\n",
            "\n",
            "4. History of AI - Artificial Intelligence - GeeksforGeeks\n",
            "   A fascinating history of human ingenuity and our persistent pursuit of creating sentient beings artificial intelligence (AI) is on the rise. There is ...\n",
            "   Read more: https://www.geeksforgeeks.org/artificial-intelligence/evolution-of-ai/\n",
            "\n",
            "5. The History of AI: A Timeline of Artificial Intelligence - Coursera\n",
            "   # The History of AI: A Timeline of Artificial Intelligence\n",
            "\n",
            "Written by Coursera Staff • Updated on\n",
            "\n",
            "In recent years, the field of artificial intellige...\n",
            "   Read more: https://www.coursera.org/articles/history-of-ai\n",
            "\n",
            "\n",
            "Query: 'Nonexistent mythical creature from obscure folklore'\n",
            "Response:\n",
            "Here's a snippet from a top result: The Wendigo: A Creepy Creature from Native American Folklore\n",
            " Medusa: The Most Feared Creature in Greek Mythology\n",
            " The Kraken: A Nightmare Mythical Creature of the Sea\n",
            " Chupacabra: A Dark Mythical Cre...\n",
            "Top results:\n",
            "1. 14 Terrifying Mythological Creatures and Their Chilling Stories\n",
            "   The Wendigo: A Creepy Creature from Native American Folklore\n",
            " Medusa: The Most Feared Creature in Greek Mythology\n",
            " The Kraken: A Nightmare Mythical Cr...\n",
            "   Read more: https://www.centreofexcellence.com/14-terrifying-mythological-creatures/\n",
            "\n",
            "2. Unseen Terrors: Exploring Rare Mythical Creatures from Folklore ...\n",
            "   Yara-Ma-Yha-Who itself. [...] Description: The Yara-Ma-Yha-Who is a bizarre vampire-like creature described as a small red man with an enormous mouth ...\n",
            "   Read more: https://medium.com/@nicholasyeager2020/unseen-terrors-exploring-rare-mythical-creatures-from-folklore-across-the-globe-a6b8500f75dc\n",
            "\n",
            "3. 7 Legendary Cryptids that Turned Out to Be Real! | Ancient Origins\n",
            "   Cryptozoology is the search for and study of animals that mainstream science considers to be mythical or non-existent. Animals studied by cryptozoolog...\n",
            "   Read more: https://www.ancient-origins.net/unexplained-phenomena/cryptids-0017386\n",
            "\n",
            "4. List of legendary creatures by type - Wikipedia\n",
            "   Gingerbread man – from German folk tales\n",
            " Golem (Jewish) – animated humanoid construct\n",
            " Homunculus (Alchemy) – diminutive, animated construct\n",
            " Nephele...\n",
            "   Read more: https://en.wikipedia.org/wiki/List_of_legendary_creatures_by_type\n",
            "\n",
            "5. The A to Z of British (and Irish) Mythological Creatures\n",
            "   K for Kelpie. A shapeshifting water spirit in Irish and Scottish folklore, this grey/white horse-like creature doesn’t transform completely but may re...\n",
            "   Read more: https://www.philparker-fantasywriter.com/post/the-a-to-z-of-british-and-irish-mythological-creatures\n",
            "\n",
            "\n",
            "Query: 'Explain quantum computing in simple terms.'\n",
            "Response:\n",
            "Here's a snippet from a top result: So, what are the basics of quantum computing? Quantum computing is a computing paradigm that relies on the principles of the quantum mechanical model. Unlike classical computing, which uses bits to re...\n",
            "Top results:\n",
            "1. Quantum Computing Basics: A Beginner's Guide\n",
            "   So, what are the basics of quantum computing? Quantum computing is a computing paradigm that relies on the principles of the quantum mechanical model....\n",
            "   Read more: https://www.bluequbit.io/quantum-computing-basics\n",
            "\n",
            "2. Quantum Computers Explained: How Quantum Computing Works\n",
            "   how different compounds will behave. In this video, we have explained quantum computing in simple words and explained how quantum computers work. [......\n",
            "   Read more: https://www.youtube.com/watch?v=B3U1NDUiwSA\n",
            "\n",
            "3. Basic Quantum Computing — Introduction\n",
            "   Before, I go and talk about the course, let’s quickly talk about what is quantum computing? Simply put quantum computing is using quantum mechanics in...\n",
            "   Read more: https://medium.com/@charlie.thomas_94667/basic-quantum-computing-introduction-f83dcfbd0e40\n",
            "\n",
            "4. What Is Quantum Computing? A Super-Easy Explanation For Anyone\n",
            "   Instead of bits, which conventional computers use, a quantum computer uses quantum bits—known as qubits. To illustrate the difference, imagine a spher...\n",
            "   Read more: https://www.forbes.com/sites/bernardmarr/2017/07/04/what-is-quantum-computing-a-super-easy-explanation-for-anyone/\n",
            "\n",
            "5. What is quantum computing and how does it work? - Iberdrola\n",
            "   A qubit (or quantum bit) is the basic unit of information in a quantum computer, equivalent to the bit in classical computing. Unlike a traditional bi...\n",
            "   Read more: https://www.iberdrola.com/about-us/our-innovation-model/what-is-quantum-computing\n",
            "\n",
            "\n",
            "Query: 'Latest discoveries about dark matter'\n",
            "Response:\n",
            "Here's a snippet from a top result: The research team – including Nick Rodd and Linda Xu, researchers in Berkeley Lab’s Physics Division, and Ben Safdi, a faculty member in UC Berkeley’s Physics Department – has been collaborating for s...\n",
            "Top results:\n",
            "1. Berkeley researchers identify a new path for the discovery of dark ...\n",
            "   The research team – including Nick Rodd and Linda Xu, researchers in Berkeley Lab’s Physics Division, and Ben Safdi, a faculty member in UC Berkeley’s...\n",
            "   Read more: https://physicalsciences.lbl.gov/2024/05/24/berkeley-researchers-identify-a-new-path-for-the-discovery-of-dark-matter/\n",
            "\n",
            "2. New analyses shine light on dark matter and intergalactic mass in ...\n",
            "   Berkeley Lab researchers have developed new ways to map the distribution patterns of dark matter and intergalactic mass in unprecedented detail, using...\n",
            "   Read more: https://physicalsciences.lbl.gov/2025/02/11/new-analyses-shine-light-on-dark-matter-and-intergalactic-mass-in-unprecedented-detail/\n",
            "\n",
            "3. Dark Matter - latest research news and features - Phys.org\n",
            "   Important as dark matter is believed to be in the universe, direct evidence of its existence and a concrete understanding of its nature have remained ...\n",
            "   Read more: https://phys.org/tags/dark+matter/\n",
            "\n",
            "4. Dark Matter might leave a 'fingerprint' on light, scientists say\n",
            "   University of York\n",
            "\n",
            "# Dark Matter might leave a ‘fingerprint’ on light, scientists say\n",
            "\n",
            "Posted on 13 October 2025\n",
            "\n",
            "Dark Matter, the substance that mak...\n",
            "   Read more: https://www.york.ac.uk/news-and-events/news/2025/research/dark-matter-light-colour/\n",
            "\n",
            "5. New theories on dark matter's origins point to 'mirror world' and ...\n",
            "   Science has produced overwhelming evidence that the mysterious substance that accounts for 80% of all matter in the universe exists. Dark matter’s pre...\n",
            "   Read more: https://news.ucsc.edu/2025/08/dark-matter-origin-theories/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c9038cc"
      },
      "source": [
        "## Subtask:\n",
        "Define the function to create some canned answers and when there is no canned answer to search online using the fetch search results function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb4629f9",
        "outputId": "8cc247de-6f0e-4a50-ad61-ac4eed572ed4"
      },
      "source": [
        "def handle_general_query(user_input):\n",
        "    \"\"\"\n",
        "    Processes a general query and provides a response based on a simple rule-based system,\n",
        "    with a fallback to web search for unknown queries.\n",
        "    \"\"\"\n",
        "    lower_input = user_input.lower()\n",
        "\n",
        "    # Simple keyword-based rule system\n",
        "    if \"what is ai\" in lower_input or \"define ai\" in lower_input:\n",
        "        return \"AI stands for Artificial Intelligence, which is the simulation of human intelligence processes by machines, especially computer systems.\"\n",
        "    elif \"capital of france\" in lower_input:\n",
        "        return \"The capital of France is Paris.\"\n",
        "    elif \"who invented the light bulb\" in lower_input:\n",
        "        return \"Thomas Edison is widely credited with inventing the practical incandescent light bulb.\"\n",
        "    elif \"how to tie a shoelace\" in lower_input:\n",
        "        return \"To tie a shoelace, make two 'bunny ears' with the laces, cross them over, and then tuck one under the other before pulling tight.\"\n",
        "    elif \"your name\" in lower_input or \"who are you\" in lower_input:\n",
        "        return \"I am an AI assistant designed to help with your queries.\"\n",
        "    elif \"hello\" in lower_input or \"hi\" in lower_input:\n",
        "        return \"Hello! How can I assist you today?\"\n",
        "    elif \"how are you\" in lower_input:\n",
        "        return \"I am an AI, so I don't have feelings, but I'm ready to help you!\"\n",
        "    else:\n",
        "        # Fallback to web search if no rule-based answer is found\n",
        "        print(f\"No direct answer found for '{user_input}'. Attempting web search...\")\n",
        "        web_search_result = fetch_web_results(user_input)\n",
        "        if web_search_result:\n",
        "            return web_search_result\n",
        "        else:\n",
        "            return \"I'm not sure how to answer that general query. Could you please rephrase it or ask something else?\"\n",
        "\n",
        "print(\"Function 'handle_general_query' updated successfully with web search fallback.\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'handle_general_query' updated successfully with web search fallback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test:\n",
        "handle_general_query"
      ],
      "metadata": {
        "id": "w0AI4mbsqKl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases for handle_general_query function\n",
        "\n",
        "print(\"--- Testing handle_general_query function ---\")\n",
        "\n",
        "# Test 1: Query matching a direct rule (AI definition)\n",
        "input_gq_1 = \"What is AI?\"\n",
        "print(f\"\\nInput: '{input_gq_1}'\")\n",
        "response_gq_1 = handle_general_query(input_gq_1)\n",
        "print(f\"Response: {response_gq_1}\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Test 2: Query matching another direct rule (Capital of France)\n",
        "input_gq_2 = \"Capital of France\"\n",
        "print(f\"\\nInput: '{input_gq_2}'\")\n",
        "response_gq_2 = handle_general_query(input_gq_2)\n",
        "print(f\"Response: {response_gq_2}\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Test 3: Query matching a rule (Who invented the light bulb)\n",
        "input_gq_3 = \"Who invented the light bulb?\"\n",
        "print(f\"\\nInput: '{input_gq_3}'\")\n",
        "response_gq_3 = handle_general_query(input_gq_3)\n",
        "print(f\"Response: {response_gq_3}\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Test 4: Query triggering web search fallback (tallest mountain)\n",
        "input_gq_4 = \"What is the tallest mountain in the world?\"\n",
        "print(f\"\\nInput: '{input_gq_4}'\")\n",
        "response_gq_4 = handle_general_query(input_gq_4)\n",
        "print(f\"Response:\\n{response_gq_4}\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Test 5: Query triggering web search fallback (more complex)\n",
        "input_gq_5 = \"Explain the theory of relativity.\"\n",
        "print(f\"\\nInput: '{input_gq_5}'\")\n",
        "response_gq_5 = handle_general_query(input_gq_5)\n",
        "print(f\"Response:\\n{response_gq_5}\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Test 6: Unknown query that might not yield good web results\n",
        "input_gq_6 = \"What color is happiness?\"\n",
        "print(f\"\\nInput: '{input_gq_6}'\")\n",
        "response_gq_6 = handle_general_query(input_gq_6)\n",
        "print(f\"Response:\\n{response_gq_6}\")\n",
        "time.sleep(2)\n",
        "\n",
        "# Test 7: Friendly greeting matching a direct rule\n",
        "input_gq_7 = \"Hello\"\n",
        "print(f\"\\nInput: '{input_gq_7}'\")\n",
        "response_gq_7 = handle_general_query(input_gq_7)\n",
        "print(f\"Response: {response_gq_7}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvg6RYQbqQCA",
        "outputId": "d7868f51-4207-4b79-8c4c-6398dcf52e67"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing handle_general_query function ---\n",
            "\n",
            "Input: 'What is AI?'\n",
            "Response: AI stands for Artificial Intelligence, which is the simulation of human intelligence processes by machines, especially computer systems.\n",
            "\n",
            "Input: 'Capital of France'\n",
            "Response: The capital of France is Paris.\n",
            "\n",
            "Input: 'Who invented the light bulb?'\n",
            "Response: Thomas Edison is widely credited with inventing the practical incandescent light bulb.\n",
            "\n",
            "Input: 'What is the tallest mountain in the world?'\n",
            "No direct answer found for 'What is the tallest mountain in the world?'. Attempting web search...\n",
            "Response:\n",
            "Here's a snippet from a top result: Mauna Kea, a shield volcano in Hawaii, is technically the world's tallest mountain from base to peak. However, its underwater base is far below sea level, so it doesn’t reach the elevation that Mount ...\n",
            "Top results:\n",
            "1. What is the tallest mountain in the world? Why it's up ... - USA Today\n",
            "   Mauna Kea, a shield volcano in Hawaii, is technically the world's tallest mountain from base to peak. However, its underwater base is far below sea le...\n",
            "   Read more: https://www.usatoday.com/story/news/2023/03/21/worlds-tallest-mountain/11504402002/\n",
            "\n",
            "2. The Top 10 Highest Mountains in the World - Much Better Adventures\n",
            "   What is the highest mountain in the world? It's Mount Everest, sitting pretty at 8,848m in the Himalayas of Nepal. It's likely you already knew that. ...\n",
            "   Read more: https://www.muchbetteradventures.com/magazine/highest-mountains-in-the-world-top-10/\n",
            "\n",
            "3. List of Tallest Mountains in The World - Climbing Kilimanjaro\n",
            "   Cho Oyu is the 6th tallest mountain in the world above sea level measuring at an elevation of 8188 meters or 26864 ft. This is another massive formati...\n",
            "   Read more: https://www.climbing-kilimanjaro.com/tallest-mountains-in-the-world/\n",
            "\n",
            "4. List of highest mountains on Earth - Wikipedia\n",
            "   The bases of mountain islands are below sea level, and given this consideration. Mauna Kea (4,207 m (13,802 ft) above sea level) is the world's talles...\n",
            "   Read more: https://en.wikipedia.org/wiki/List_of_highest_mountains_on_Earth\n",
            "\n",
            "5. Is Mount Everest Really the Tallest Mountain in the World? | Britannica\n",
            "   Other mountains, though, have made claims on being the tallest when measured from points other than sea level. Chimborazo in Ecuador, for example, has...\n",
            "   Read more: https://www.britannica.com/story/is-mount-everest-really-the-tallest-mountain-in-the-world\n",
            "\n",
            "\n",
            "Input: 'Explain the theory of relativity.'\n",
            "No direct answer found for 'Explain the theory of relativity.'. Attempting web search...\n",
            "Response:\n",
            "Here's a snippet from a top result: Relativity is two related theories: special relativity, which explains the relationship between space, time, mass, and energy; and general relativity, which describes how gravity fits into the mix. Al...\n",
            "Top results:\n",
            "1. DOE Explains...Relativity - Department of Energy\n",
            "   Relativity is two related theories: special relativity, which explains the relationship between space, time, mass, and energy; and general relativity,...\n",
            "   Read more: https://www.energy.gov/science/doe-explainsrelativity\n",
            "\n",
            "2. Theory of relativity - Wikipedia\n",
            "   The term \"theory of relativity\" was based on the expression \"relative theory\" (German: Relativtheorie) used in 1906 by Planck, who emphasized how the ...\n",
            "   Read more: https://en.wikipedia.org/wiki/Theory_of_relativity\n",
            "\n",
            "3. Einstein's Theory Of Relativity - Dr. Binocs Show - YouTube\n",
            "   # Einstein's Theory Of Relativity | The Curvature of Spacetime | General Relativity | Dr. Binocs Show\n",
            "## Peekaboo Kidz\n",
            "6940000 subscribers\n",
            "2392 likes\n",
            "...\n",
            "   Read more: https://www.youtube.com/watch?v=gKS2eD8iyuo\n",
            "\n",
            "4. What is the theory of general relativity? Understanding Einstein's ...\n",
            "   General relativity is physicist Albert Einstein's understanding of how gravity affects the fabric of space-time.\n",
            "\n",
            "The theory, which Einstein published...\n",
            "   Read more: https://www.space.com/17661-theory-general-relativity.html\n",
            "\n",
            "5. Einstein's Theory of Gravitation | Center for Astrophysics - Harvard CfA\n",
            "   Albert Einstein published his full theory of general relativity in 1915, followed by a flurry of research papers by Einstein and others exploring the ...\n",
            "   Read more: https://www.cfa.harvard.edu/research/science-field/einsteins-theory-gravitation\n",
            "\n",
            "\n",
            "Input: 'What color is happiness?'\n",
            "No direct answer found for 'What color is happiness?'. Attempting web search...\n",
            "Response:\n",
            "Here's a snippet from a top result: So, what color represents happiness? Yellow, with its sunny, vibrant energy, stands out as the ultimate symbol of joy across cultures and contexts. But happiness is multi-faceted, and colors like oran...\n",
            "Top results:\n",
            "1. What Color Represents Happiness? - Bookcoverart\n",
            "   So, what color represents happiness? Yellow, with its sunny, vibrant energy, stands out as the ultimate symbol of joy across cultures and contexts. Bu...\n",
            "   Read more: https://www.bookcoverart.co/blog/what-color-represents-happiness\n",
            "\n",
            "2. How Seasonal Colors Affect Your Mood - Beyond Healing Counseling\n",
            "   Yellow for Happiness and Focus: Yellow is a mood-boosting color associated with positivity and clarity. Adding yellow accents to your home or workspac...\n",
            "   Read more: https://beyondhealingcounseling.com/how-seasonal-colors-affect-your-mood/\n",
            "\n",
            "3. Color Psychology: How Colors Affect Your Mood and Happiness\n",
            "   Pink is often seen as a nurturing and gentle color, linked to feelings of love and kindness. Softer shades can create a sense of comfort, while bright...\n",
            "   Read more: https://www.happiness-posts.com/happiness-blog/color-psychology-how-colors-affect-your-mood-and-happiness\n",
            "\n",
            "4. The Psychology of the Color Yellow - Verywell Mind\n",
            "   ## Yellow Is Cheerful\n",
            "\n",
            "For many people, yellow is seen as a bright and cheerful color. Advertisers may use it to not only draw attention but also to e...\n",
            "   Read more: https://www.verywellmind.com/the-color-psychology-of-yellow-2795823\n",
            "\n",
            "5. The psychology of colors - how wall colors affect our mood - Samplize\n",
            "   Yellow is often associated with sunshine and happiness and is known to stimulate mental activity and promote optimism. It is often used in classrooms ...\n",
            "   Read more: https://samplize.com/blogs/posts/psychology-of-colors-how-wall-colors-affect-our-mood\n",
            "\n",
            "\n",
            "Input: 'Hello'\n",
            "Response: Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf1b3cab"
      },
      "source": [
        "##Subtask:\n",
        "Define chatbot response function to create a hierarchy of intent to search type for responce\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76e6b558",
        "outputId": "5e4af05a-6f39-4764-dfe9-544d33d29016"
      },
      "source": [
        "def chatbot_response(user_input):\n",
        "    \"\"\"\n",
        "    Main function to process user input, determine intent, and provide a response.\n",
        "    \"\"\"\n",
        "    intent = recognize_intent(user_input)\n",
        "\n",
        "    if intent == \"general_query\":\n",
        "        response = handle_general_query(user_input)\n",
        "    elif intent == \"news_request\":\n",
        "        response = handle_news_request(user_input)\n",
        "        # Add a small delay after a news request to avoid hitting API rate limits\n",
        "        time.sleep(2) # Sleep for 2 seconds\n",
        "    else:\n",
        "        response = \"I'm sorry, I don't understand that request. Can you please rephrase it?\"\n",
        "\n",
        "    return response\n",
        "\n",
        "print(\"Main chatbot response function 'chatbot_response' defined successfully.\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main chatbot response function 'chatbot_response' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b367ab0c"
      },
      "source": [
        "###Test\n",
        "chatbot_responce"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3daa9d2",
        "outputId": "5a2bee2d-7fce-40c0-f7e0-31664bb5e52a"
      },
      "source": [
        "# Test with a general query\n",
        "user_input_general = \"What is the capital of France?\"\n",
        "print(f\"User: {user_input_general}\")\n",
        "response_general = chatbot_response(user_input_general)\n",
        "print(f\"Chatbot: {response_general}\\n\")\n",
        "\n",
        "# Test with another general query (that might trigger web search fallback)\n",
        "user_input_general_web = \"What is the tallest mountain in Africa?\"\n",
        "print(f\"User: {user_input_general_web}\")\n",
        "response_general_web = chatbot_response(user_input_general_web)\n",
        "print(f\"Chatbot: {response_general_web}\\n\")\n",
        "\n",
        "# Test with a news request\n",
        "user_input_news = \"Tell me the news about technology.\"\n",
        "print(f\"User: {user_input_news}\")\n",
        "response_news = chatbot_response(user_input_news)\n",
        "print(f\"Chatbot: {response_news}\\n\")\n",
        "\n",
        "# Test with another news request\n",
        "user_input_news_2 = \"What are the latest updates on space exploration?\"\n",
        "print(f\"User: {user_input_news_2}\")\n",
        "response_news_2 = chatbot_response(user_input_news_2)\n",
        "print(f\"Chatbot: {response_news_2}\\n\")\n",
        "\n",
        "# Add more test cases for news requests\n",
        "user_input_news_3 = \"news on current events\"\n",
        "print(f\"User: {user_input_news_3}\")\n",
        "response_news_3 = chatbot_response(user_input_news_3)\n",
        "print(f\"Chatbot: {response_news_3}\\n\")\n",
        "\n",
        "user_input_news_4 = \"breaking news in politics\"\n",
        "print(f\"User: {user_input_news_4}\")\n",
        "response_news_4 = chatbot_response(user_input_news_4)\n",
        "print(f\"Chatbot: {response_news_4}\\n\")\n",
        "\n",
        "user_input_news_5 = \"what's happening in the economy?\"\n",
        "print(f\"User: {user_input_news_5}\")\n",
        "response_news_5 = chatbot_response(user_input_news_5)\n",
        "print(f\"Chatbot: {response_news_5}\\n\")\n",
        "\n",
        "user_input_news_6 = \"today's headlines\"\n",
        "print(f\"User: {user_input_news_6}\")\n",
        "response_news_6 = chatbot_response(user_input_news_6)\n",
        "print(f\"Chatbot: {response_news_6}\\n\")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is the capital of France?\n",
            "Chatbot: The capital of France is Paris.\n",
            "\n",
            "User: What is the tallest mountain in Africa?\n",
            "No direct answer found for 'What is the tallest mountain in Africa?'. Attempting web search...\n",
            "Chatbot: Here's a snippet from a top result: The highest African mountain is Kilimanjaro, which has three peaks, named Kibo, Mawenzi and Shira, of which Kibo is the tallest and Mawenzi is sufficiently prominent to be a mountain. Mount Kenya is t...\n",
            "Top results:\n",
            "1. List of highest major summits of Africa - Wikipedia\n",
            "   The highest African mountain is Kilimanjaro, which has three peaks, named Kibo, Mawenzi and Shira, of which Kibo is the tallest and Mawenzi is suffici...\n",
            "   Read more: https://en.wikipedia.org/wiki/List_of_highest_major_summits_of_Africa\n",
            "\n",
            "2. Kilimanjaro - National Geographic Education\n",
            "   Located in Tanzania, Mount Kilimanjaro is the African continent's highest peak at 5,895 meters (19,340 feet). The majestic mountain is a snow-capped v...\n",
            "   Read more: https://education.nationalgeographic.org/resource/kilimanjaro/\n",
            "\n",
            "3. Mount Kilimanjaro - Wikipedia\n",
            "   Mount Kilimanjaro (/ˌkɪlɪmənˈdʒɑːroʊ/) is a large dormant volcano in Tanzania. It is the highest mountain in Africa and the highest free-standing moun...\n",
            "   Read more: https://en.wikipedia.org/wiki/Mount_Kilimanjaro\n",
            "\n",
            "4. How high is Mount Kilimanjaro, and why is it considered to be one of ...\n",
            "   What is grown on the lower slopes of Mount Kilimanjaro?\n",
            "\n",
            "Is climbing Mount Kilimanjaro dangerous for a person with heart problems or high blood pressu...\n",
            "   Read more: https://www.quora.com/How-high-is-Mount-Kilimanjaro-and-why-is-it-considered-to-be-one-of-the-Seven-Summits\n",
            "\n",
            "5. Kilimanjaro : Climb Africa's Highest Mountain 5895 M (19341 feet)\n",
            "   The Peaks of Kilimanjaro\n",
            "Towering over Africa and the rest of the world, Mount Kilimanjaro stands at a staggering height of 5,895 metres (19,341 feet)...\n",
            "   Read more: https://www.youtube.com/watch?v=cKKr6k3KnNA\n",
            "\n",
            "\n",
            "User: Tell me the news about technology.\n",
            "Chatbot: 1. New Buy Rating for Beijing Fourth Paradigm Technology Co. Ltd. Class H (6682), the Technology Giant\n",
            "   In a report released yesterday, from Huatai Securities maintained a Buy rating on Beijing Fourth Paradigm Technology Co. Ltd. Class H, with a p...\n",
            "   Read more: https://markets.businessinsider.com/news/stocks/new-buy-rating-for-beijing-fourth-paradigm-technology-co-ltd-class-h-6682-the-technology-giant-1035564722\n",
            "\n",
            "2. US jury says Apple must pay Masimo $634 million in smartwatch patent case\n",
            "   A federal jury in California said on Friday that Apple owes medical-monitoring technology company Masimo $634 million for infringing a patent covering blood-oxygen reading technology.\n",
            "   Read more: https://www.reuters.com/business/us-jury-says-apple-must-pay-masimo-634-million-smartwatch-patent-case-2025-11-15/\n",
            "\n",
            "3. This smartwatch can monitor your blood pressure, but it's not for everyone - here's why\n",
            "   Wrist-based blood pressure monitoring is a developing technology, but the YHE BP Doctor Med is a product that could help some people.\n",
            "   Read more: https://www.zdnet.com/article/this-smartwatch-can-monitor-your-blood-pressure-but-its-not-for-everyone-heres-why/\n",
            "\n",
            "4. New Buy Rating for Xiaomi (XIACF), the Technology Giant\n",
            "   Bernstein analyst Eunice Lee maintained a Buy rating on Xiaomi on November 12 and set a price target of HK$57.00. The company’s shares closed ye...\n",
            "   Read more: https://markets.businessinsider.com/news/stocks/new-buy-rating-for-xiaomi-xiacf-the-technology-giant-1035564587\n",
            "\n",
            "5. Evolving Skies: Anti-drone technology used on Ukrainian battlefields, in NATO airspace after flyovers\n",
            "   AALBORG, Denmark — In a warehouse more than 900 miles from Ukraine’s capital, workers in northern Denmark painstakingly piece together anti-drone devices. Some of the devices will be exported to Kyiv in the hopes of jamming Russian technology on the battlefield, while others will be shipped across Europe in efforts to combat mysterious drone intrusions […]\n",
            "   Read more: https://www.altoonamirror.com/news/international-news-apwire/2025/11/denmark-ukraine-anti-drone-tech-battlefields-flyovers/\n",
            "\n",
            "\n",
            "User: What are the latest updates on space exploration?\n",
            "Chatbot: 1. What Does 'NASA' Stand For?\n",
            "   NASA has been the leader of our air and space exploration for decades, but what does the name stand for and where did it come from? Here's what we know.\n",
            "   Read more: https://www.bgr.com/2019863/what-nasa-name-means-stand-for-explained/\n",
            "\n",
            "2. 5 Of The Most Expensive NASA Space Missions In History\n",
            "   Space exploration has changed how we look at the universe, but it's costly, and some of the most iconic NASA missions are also among the most expensive.\n",
            "   Read more: https://www.bgr.com/2019315/most-expensive-nasa-space-missions-ever/\n",
            "\n",
            "3. The Future of Design: How CAD Software Is Shaping the Next Wave of Innovation\n",
            "   When we think of the most important innovations of the recent decades, in architecture, engineering, and space exploration, we can’t ignore the innovation that made it all possible - CAD Software. Once a niche solution for blueprints and 2D technical drawings, Computer-Aided Design (CAD) has been evolving into a much larger digital environment that changes\n",
            "   Read more: https://techstartups.com/2025/11/13/the-future-of-design-how-cad-software-is-shaping-the-next-wave-of-innovation/\n",
            "\n",
            "4. Intuitive Machines sees Lanteris deal creating new opportunities in defense and exploration\n",
            "   Intuitive Machines says its acquisition of satellite manufacturer Lanteris Space Systems will open new opportunities for the company.\n",
            "   Read more: https://spacenews.com/intuitive-machines-sees-lanteris-deal-creating-new-opportunities-in-defense-and-exploration/\n",
            "\n",
            "5. LOST IN ORBIT: Chinese Astronauts Stranded in Tiangong Space Station After Debris Strikes Their Return Capsule\n",
            "   This is a distressing trend in space exploration.\n",
            "   Read more: https://www.thegatewaypundit.com/2025/11/lost-orbit-chinese-astronauts-stranded-tiangong-space-station/\n",
            "\n",
            "\n",
            "User: news on current events\n",
            "Chatbot: 1. Orange County scores and player stats for Friday, Nov. 14\n",
            "   Scores and stats from Orange County games on Friday, Nov. 14\n",
            "   Read more: https://www.ocregister.com/2025/11/14/orange-county-scores-and-player-stats-for-friday-nov-14/\n",
            "\n",
            "2. Sanju Samson finally speaks on Rajasthan Royals after joining CSK\n",
            "   Sanju Samson has finally reacted to his blockbuster move to Chennai Super Kings (CSK) ahead of the IPL 2026, and his message has left Rajasthan Royals (RR) fans emotional.\n",
            "   Read more: https://cricketaddictor.com/cricket-news/sanju-samson-finally-speaks-on-rajasthan-royals-after-joining-csk-292438/\n",
            "\n",
            "3. Mark Zuckerberg-Led Meta To Reportedly Grade Employees On 'AI-Driven Impact' As Big Tech Declares Human-AI Hybrid Work 'No Longer Optional'\n",
            "   Meta Platforms Inc is reportedly preparing to evaluate employees based on their ability to drive results using artificial intelligence.\n",
            "   Read more: https://www.benzinga.com/markets/tech/25/11/48885383/mark-zuckerberg-led-meta-to-reportedly-grade-employees-on-ai-driven-impact-as-big-tech-declares-human-ai-hybrid-work-no-longer-optional\n",
            "\n",
            "4. Channing Ridley shining with speed for DeWitt football\n",
            "   Sophomore scored on a kick return, a run and had a TD reception for Panthers in 70-26 win.\n",
            "   Read more: https://www.lansingstatejournal.com/story/sports/high-school/2025/11/15/dewitt-fenton-football-division3-regional-final-channing-ridley/87284130007/\n",
            "\n",
            "5. Colorado Buffaloes soccer takes on Utah Valley in NCAA Tournament first round\n",
            "   The Colorado Buffaloes women's soccer team matched up with Utah Valley on Friday night at Prentup Field looking to secure an NCAA Tournament win.\n",
            "   Read more: https://www.denverpost.com/2025/11/14/colorado-buffaloes-womens-soccer-utah-valley-ncaa/\n",
            "\n",
            "\n",
            "User: breaking news in politics\n",
            "Chatbot: 1. The Reuters Institute developed a typology of news influencers.\n",
            "   The survey offers a fascinating look at the modern landscape of news creators and influencers. It offers a taxonomy of news creators, breaking them down into four types of content: commentary, news/investigation, explanation, and specialism. Unsurprisingly, it also found that younger generations have shifted away from traditional media, towards creators and personalities, and that partisan content often outflanks more balanced approaches.\n",
            "[Image: https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/Typology_0.jpg?quality=90&strip=all]\n",
            "[Link: Mapping news creators and influencers in social and video networks | https://reutersinstitute.politics.ox.ac.uk/news-creators-influencers/2025/mapping-news-creators-and-influencers-social-and-video-networks#five | Reuters Institute for the Study of Journalism]\n",
            "   Read more: https://www.theverge.com/news/812078/the-reuters-institute-developed-a-typology-of-news-influencers\n",
            "\n",
            "2. Emma Stone Brags About Not Breaking Bones for Film 'Bugonia'\n",
            "   US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, and find news you can use in politics, business, health, and education.\n",
            "   Read more: https://www.usnews.com/news/top-news/articles/2025-10-22/emma-stone-brags-about-not-breaking-bones-for-film-bugonia\n",
            "\n",
            "\n",
            "User: what's happening in the economy?\n",
            "Chatbot: 1. Lee Zeldin to Newsmax: Trump's EPA Protects Environment, Economy\n",
            "   Zeldin told Finnerty that the Trump EPA is moving faster on deregulation than “entire federal governments in the past.”\n",
            "   Read more: https://www.newsmax.com/politics/lee-zeldin-newsmax-trump-epa/2025/11/14/id/1234662/\n",
            "\n",
            "2. Zeldin to Newsmax: Trump's EPA Protects Environment, Economy\n",
            "   Zeldin told Finnerty that the Trump EPA is moving faster on deregulation than “entire federal governments in the past.”\n",
            "   Read more: https://www.newsmax.com/newsmax-tv/lee-zeldin-newsmax-trump-epa/2025/11/14/id/1234662/\n",
            "\n",
            "3. Trump scraps tariffs on certain items in effort to lower grocery prices\n",
            "   Trump had focused on tariffs to boost domestic production and the economy. but the recent elections showed economic concerns as a top issue, with Democrats gaining wins.\n",
            "   Read more: https://www.pennlive.com/politics/2025/11/trump-scraps-tariffs-on-certain-items-in-effort-to-lower-grocery-prices.html\n",
            "\n",
            "4. Trump announces tariff cuts on food, citing high prices\n",
            "   “The Trump administration is desperately searching around for a solution to their political situation and they found one that is a truly brilliant idea,\" says Chris Hayes. \"‘How about we remove some of the tariffs on goods people buy that are driving prices up?’ Now, if only they could find the clown that imposed those tariffs in the first place.” Rep. Brendan Boyle responds to the news, adding, “the brilliance will take your breath away. Congratulations President Trump for putting out part of the fire that you yourself started about six months ago, but already, damage has been done to our economy.”\n",
            "   Read more: https://www.msnbc.com/all-in/watch/trump-announces-tariff-cuts-on-food-citing-high-prices-252104261690\n",
            "\n",
            "5. Planet Money : NPR\n",
            "   Last month, during the longest government shutdown in U.S. history, Treasury Secretary Scott Bessent announced that the United States had offered to functionally loan Argentina $20 billion. Despite the sums involved, this bailout required no authorization from Congress, because of the loan’s source: an obscure pool of money called the Exchange Stabilization Fund. The ESF is essentially the Treasury Department’s private slush fund. Its history goes all the way back to the Great Depression. But, in the 90 years since its creation, it has only been used one time at this scale to bailout an emerging economy: Mexico, in 1995. That case study contains some helpful lessons that can be used to make sense of Bessent’s recent move. Will this new credit line to Argentina work out as well as it did the last time we tried it? Or will Argentina’s economic troubles hamstring the Exchange Stabilization Fund forever?Pre-order the Planet Money book and get a free gift. /  Subscribe to Planet Money+Listen free: Apple Podcasts, Spotify, the NPR app or anywhere you get podcasts.Facebook / Instagram / TikTok / Our weekly Newsletter.This episode was hosted by Keith Romer and Erika Beras. It was produced by Luis Gallo. It was edited by Eric Mennel and fact checked by Sierra Juarez. It was engineered by Cena Loffredo. Alex Goldmark is Planet Money’s executive producer.\n",
            "   Read more: https://www.npr.org/2025/11/14/nx-s1-5609382/argentina-loan-bessent-treasury-bailout\n",
            "\n",
            "\n",
            "User: today's headlines\n",
            "Chatbot: 1. Full Menus for 2025 Festival of the Holidays In Todays Daily Recap For 11/4/25\n",
            "   Full Menus for 2025 Festival of the Holidays In Todays Daily Recap For 11/4/25\n",
            "   Read more: https://wdwnt.com/2025/11/full-menus-for-2025-festival-of-the-holidays-daily-recap-11-4-25/\n",
            "\n",
            "2. Pure Hedge - Livestock and Grain\n",
            "   Grains About to Trade Higher - Cattle Markets Could be in Trouble + TODAYS FEEDER CATTLE TRADES + YESTERDAYS LIVE CATTLE TRADES\n",
            "   Read more: https://www.barchart.com/story/news/35900035/pure-hedge-livestock-and-grain\n",
            "\n",
            "3. Pure Hedge - Livestock and Grain\n",
            "   Grains About to Trade Higher - Cattle Markets Could be in Trouble + TODAYS FEEDER CATTLE TRADES + YESTERDAYS LIVE CATTLE TRADES\n",
            "   Read more: https://www.barchart.com/story/news/35900034/pure-hedge-livestock-and-grain\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Impliment workflow"
      ],
      "metadata": {
        "id": "Vqk2diMZuHrR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xZyNHE3kuI6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b26c3ee6"
      },
      "source": [
        "# Task\n",
        "Refactor the existing chatbot's intent handling and response generation using `langgraph`, including defining a graph state, creating nodes for `recognize_intent`, `handle_general_query`, and `handle_news_request`, implementing conditional routing, building and compiling the graph, and integrating it into the `chatbot_response` function, while preserving the existing functionality and the `time.sleep` for news requests, then re-running the chatbot tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56e13139"
      },
      "source": [
        "## Install LangGraph and define graph state\n",
        "\n",
        "### Subtask:\n",
        "Install the `langgraph` library and define the `GraphState` using TypedDict to manage the state passed between nodes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000288be"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing the `langgraph` library and defining a `GraphState` using `TypedDict`. This code block will perform both actions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ad8bdb",
        "outputId": "e636b02e-c6f8-4d33-8947-9aea1ec8781d"
      },
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph. Used to pass information between nodes.\n",
        "    \"\"\"\n",
        "    user_input: str\n",
        "    intent: str\n",
        "    response: str\n",
        "\n",
        "print(\"LangGraph installed and GraphState defined successfully.\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.5 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n",
            "LangGraph installed and GraphState defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d002d48c"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to define the nodes for the LangGraph workflow, which will encapsulate the existing functions (`recognize_intent`, `handle_general_query`, and `handle_news_request`). Each node will take the `GraphState` as input and update it with the results of its operation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e07e07a6",
        "outputId": "05185381-5d68-4a8f-a3dd-66463cb62159"
      },
      "source": [
        "def intent_recognition_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to recognize the intent of the user input.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    intent = recognize_intent(user_input)\n",
        "    return {\"intent\": intent}\n",
        "\n",
        "def general_query_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle general queries.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_general_query(user_input)\n",
        "    return {\"response\": response}\n",
        "\n",
        "def news_request_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle news requests.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_news_request(user_input)\n",
        "    time.sleep(2) # Preserve the delay\n",
        "    return {\"response\": response}\n",
        "\n",
        "print(\"LangGraph nodes defined successfully.\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraph nodes defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9d448bc"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the nodes are defined, I need to define the conditional routing logic using `langgraph` to connect these nodes. This involves importing `StateGraph`, creating a graph, adding the nodes, setting the entry point, defining the conditional edges based on the intent, and compiling the graph.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ccce309",
        "outputId": "94e2e4b9-ba0f-4c10-9d5e-eb616e7209b2"
      },
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def route_intent(state: GraphState):\n",
        "    \"\"\"\n",
        "    Conditional edge based on intent.\n",
        "    \"\"\"\n",
        "    if state[\"intent\"] == \"general_query\":\n",
        "        return \"general_query_handler\"\n",
        "    elif state[\"intent\"] == \"news_request\":\n",
        "        return \"news_request_handler\"\n",
        "    else:\n",
        "        return \"general_query_handler\" # Fallback if intent is not recognized or an unexpected value\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"intent_recognizer\", intent_recognition_node)\n",
        "workflow.add_node(\"general_query_handler\", general_query_node)\n",
        "workflow.add_node(\"news_request_handler\", news_request_node)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"intent_recognizer\")\n",
        "\n",
        "# Add conditional edges from the intent recognizer\n",
        "workflow.add_conditional_edges(\n",
        "    \"intent_recognizer\",\n",
        "    route_intent,\n",
        "    {\n",
        "        \"general_query_handler\": \"general_query_handler\",\n",
        "        \"news_request_handler\": \"news_request_handler\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Set end points for the handlers\n",
        "workflow.add_edge(\"general_query_handler\", END)\n",
        "workflow.add_edge(\"news_request_handler\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"LangGraph workflow compiled successfully.\")"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangGraph workflow compiled successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a43a202"
      },
      "source": [
        "**Reasoning**:\n",
        "The next logical step is to integrate the newly compiled `langgraph` workflow into the `chatbot_response` function, replacing the old conditional logic with the graph execution. This will complete the refactoring of the chatbot's core logic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "483a66e3",
        "outputId": "b658313d-af20-4f14-c2a7-2e06892fa62d"
      },
      "source": [
        "def chatbot_response(user_input):\n",
        "    \"\"\"\n",
        "    Main function to process user input using the LangGraph workflow.\n",
        "    \"\"\"\n",
        "    initial_state = {\"user_input\": user_input, \"intent\": \"\", \"response\": \"\"}\n",
        "\n",
        "    # Run the graph\n",
        "    # The graph will execute nodes: intent_recognizer -> (general_query_handler OR news_request_handler)\n",
        "    # and update the state.\n",
        "    for s in app.stream(initial_state):\n",
        "        # s contains the state after each step in the graph\n",
        "        final_state = s\n",
        "\n",
        "    return final_state.get(\"response\", \"I'm sorry, something went wrong and I couldn't process your request.\")\n",
        "\n",
        "print(\"Main chatbot response function 'chatbot_response' updated to use LangGraph successfully.\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main chatbot response function 'chatbot_response' updated to use LangGraph successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b030bd83"
      },
      "source": [
        "**Reasoning**:\n",
        "The `chatbot_response` function has been refactored to use `langgraph`. Now, it is crucial to re-run the existing test cases for `chatbot_response` to verify that the refactoring maintained the intended functionality and that the bot responds correctly to both general queries and news requests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5303fb9c",
        "outputId": "47416a89-58b5-4622-97f7-785549652d37"
      },
      "source": [
        "import time\n",
        "\n",
        "# Test with a general query\n",
        "user_input_general = \"What is the capital of France?\"\n",
        "print(f\"User: {user_input_general}\")\n",
        "response_general = chatbot_response(user_input_general)\n",
        "print(f\"Chatbot: {response_general}\\n\")\n",
        "\n",
        "# Test with another general query (that might trigger web search fallback)\n",
        "user_input_general_web = \"What is the tallest mountain in Africa?\"\n",
        "print(f\"User: {user_input_general_web}\")\n",
        "response_general_web = chatbot_response(user_input_general_web)\n",
        "print(f\"Chatbot: {response_general_web}\\n\")\n",
        "\n",
        "# Test with a news request\n",
        "user_input_news = \"Tell me the news about technology.\"\n",
        "print(f\"User: {user_input_news}\")\n",
        "response_news = chatbot_response(user_input_news)\n",
        "print(f\"Chatbot: {response_news}\\n\")\n",
        "\n",
        "# Test with another news request\n",
        "user_input_news_2 = \"What are the latest updates on space exploration?\"\n",
        "print(f\"User: {user_input_news_2}\")\n",
        "response_news_2 = chatbot_response(user_input_news_2)\n",
        "print(f\"Chatbot: {response_news_2}\\n\")\n",
        "\n",
        "# Add more test cases for news requests\n",
        "user_input_news_3 = \"news on current events\"\n",
        "print(f\"User: {user_input_news_3}\")\n",
        "response_news_3 = chatbot_response(user_input_news_3)\n",
        "print(f\"Chatbot: {response_news_3}\\n\")\n",
        "\n",
        "user_input_news_4 = \"breaking news in politics\"\n",
        "print(f\"User: {user_input_news_4}\")\n",
        "response_news_4 = chatbot_response(user_input_news_4)\n",
        "print(f\"Chatbot: {response_news_4}\\n\")\n",
        "\n",
        "user_input_news_5 = \"what's happening in the economy?\"\n",
        "print(f\"User: {user_input_news_5}\")\n",
        "response_news_5 = chatbot_response(user_input_news_5)\n",
        "print(f\"Chatbot: {response_news_5}\\n\")\n",
        "\n",
        "user_input_news_6 = \"today's headlines\"\n",
        "print(f\"User: {user_input_news_6}\")\n",
        "response_news_6 = chatbot_response(user_input_news_6)\n",
        "print(f\"Chatbot: {response_news_6}\\n\")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is the capital of France?\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: What is the tallest mountain in Africa?\n",
            "No direct answer found for 'What is the tallest mountain in Africa?'. Attempting web search...\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: Tell me the news about technology.\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: What are the latest updates on space exploration?\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: news on current events\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: breaking news in politics\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: what's happening in the economy?\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n",
            "User: today's headlines\n",
            "Chatbot: I'm sorry, something went wrong and I couldn't process your request.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59a71ecf"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous test results indicate that the `chatbot_response` function is not correctly extracting the final response from the LangGraph workflow, as it consistently returns an error message. This is likely due to the way `app.stream` is being used. Using `app.invoke()` will directly execute the graph and return the final state, which should contain the generated response.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f800151",
        "outputId": "c470f760-55f5-42ef-bb48-41f3da55ee60"
      },
      "source": [
        "def chatbot_response(user_input):\n",
        "    \"\"\"\n",
        "    Main function to process user input using the LangGraph workflow.\n",
        "    \"\"\"\n",
        "    initial_state = {\"user_input\": user_input, \"intent\": \"\", \"response\": \"\"}\n",
        "\n",
        "    # Run the graph directly to get the final state\n",
        "    final_state = app.invoke(initial_state)\n",
        "\n",
        "    return final_state.get(\"response\", \"I'm sorry, something went wrong and I couldn't process your request.\")\n",
        "\n",
        "print(\"Main chatbot response function 'chatbot_response' updated to use LangGraph's invoke method.\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main chatbot response function 'chatbot_response' updated to use LangGraph's invoke method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a432b39"
      },
      "source": [
        "**Reasoning**:\n",
        "The `chatbot_response` function has been updated to use `app.invoke()`, which is expected to resolve the issue of not correctly extracting the final response from the LangGraph workflow. It is crucial to re-run the existing test cases to verify that the refactoring maintained the intended functionality and that the bot responds correctly to both general queries and news requests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0103f0bd",
        "outputId": "f87ae605-a567-4b5b-f72a-000a4adcf912"
      },
      "source": [
        "import time\n",
        "\n",
        "# Test with a general query\n",
        "user_input_general = \"What is the capital of France?\"\n",
        "print(f\"User: {user_input_general}\")\n",
        "response_general = chatbot_response(user_input_general)\n",
        "print(f\"Chatbot: {response_general}\\n\")\n",
        "\n",
        "# Test with another general query (that might trigger web search fallback)\n",
        "user_input_general_web = \"What is the tallest mountain in Africa?\"\n",
        "print(f\"User: {user_input_general_web}\")\n",
        "response_general_web = chatbot_response(user_input_general_web)\n",
        "print(f\"Chatbot: {response_general_web}\\n\")\n",
        "\n",
        "# Test with a news request\n",
        "user_input_news = \"Tell me the news about technology.\"\n",
        "print(f\"User: {user_input_news}\")\n",
        "response_news = chatbot_response(user_input_news)\n",
        "print(f\"Chatbot: {response_news}\\n\")\n",
        "\n",
        "# Test with another news request\n",
        "user_input_news_2 = \"What are the latest updates on space exploration?\"\n",
        "print(f\"User: {user_input_news_2}\")\n",
        "response_news_2 = chatbot_response(user_input_news_2)\n",
        "print(f\"Chatbot: {response_news_2}\\n\")\n",
        "\n",
        "# Add more test cases for news requests\n",
        "user_input_news_3 = \"news on current events\"\n",
        "print(f\"User: {user_input_news_3}\")\n",
        "response_news_3 = chatbot_response(user_input_news_3)\n",
        "print(f\"Chatbot: {response_news_3}\\n\")\n",
        "\n",
        "user_input_news_4 = \"breaking news in politics\"\n",
        "print(f\"User: {user_input_news_4}\")\n",
        "response_news_4 = chatbot_response(user_input_news_4)\n",
        "print(f\"Chatbot: {response_news_4}\\n\")\n",
        "\n",
        "user_input_news_5 = \"what's happening in the economy?\"\n",
        "print(f\"User: {user_input_news_5}\")\n",
        "response_news_5 = chatbot_response(user_input_news_5)\n",
        "print(f\"Chatbot: {response_news_5}\\n\")\n",
        "\n",
        "user_input_news_6 = \"today's headlines\"\n",
        "print(f\"User: {user_input_news_6}\")\n",
        "response_news_6 = chatbot_response(user_input_news_6)\n",
        "print(f\"Chatbot: {response_news_6}\\n\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is the capital of France?\n",
            "Chatbot: The capital of France is Paris.\n",
            "\n",
            "User: What is the tallest mountain in Africa?\n",
            "No direct answer found for 'What is the tallest mountain in Africa?'. Attempting web search...\n",
            "Chatbot: Here's a snippet from a top result: The highest African mountain is Kilimanjaro, which has three peaks, named Kibo, Mawenzi and Shira, of which Kibo is the tallest and Mawenzi is sufficiently prominent to be a mountain. Mount Kenya is t...\n",
            "Top results:\n",
            "1. List of highest major summits of Africa - Wikipedia\n",
            "   The highest African mountain is Kilimanjaro, which has three peaks, named Kibo, Mawenzi and Shira, of which Kibo is the tallest and Mawenzi is suffici...\n",
            "   Read more: https://en.wikipedia.org/wiki/List_of_highest_major_summits_of_Africa\n",
            "\n",
            "2. Kilimanjaro - National Geographic Education\n",
            "   Located in Tanzania, Mount Kilimanjaro is the African continent's highest peak at 5,895 meters (19,340 feet). The majestic mountain is a snow-capped v...\n",
            "   Read more: https://education.nationalgeographic.org/resource/kilimanjaro/\n",
            "\n",
            "3. Mount Kilimanjaro - Wikipedia\n",
            "   Mount Kilimanjaro (/ˌkɪlɪmənˈdʒɑːroʊ/) is a large dormant volcano in Tanzania. It is the highest mountain in Africa and the highest free-standing moun...\n",
            "   Read more: https://en.wikipedia.org/wiki/Mount_Kilimanjaro\n",
            "\n",
            "4. How high is Mount Kilimanjaro, and why is it considered to be one of ...\n",
            "   What is grown on the lower slopes of Mount Kilimanjaro?\n",
            "\n",
            "Is climbing Mount Kilimanjaro dangerous for a person with heart problems or high blood pressu...\n",
            "   Read more: https://www.quora.com/How-high-is-Mount-Kilimanjaro-and-why-is-it-considered-to-be-one-of-the-Seven-Summits\n",
            "\n",
            "5. Kilimanjaro : Climb Africa's Highest Mountain 5895 M (19341 feet)\n",
            "   The Peaks of Kilimanjaro\n",
            "Towering over Africa and the rest of the world, Mount Kilimanjaro stands at a staggering height of 5,895 metres (19,341 feet)...\n",
            "   Read more: https://www.youtube.com/watch?v=cKKr6k3KnNA\n",
            "\n",
            "\n",
            "User: Tell me the news about technology.\n",
            "Chatbot: 1. New Buy Rating for Beijing Fourth Paradigm Technology Co. Ltd. Class H (6682), the Technology Giant\n",
            "   In a report released yesterday, from Huatai Securities maintained a Buy rating on Beijing Fourth Paradigm Technology Co. Ltd. Class H, with a p...\n",
            "   Read more: https://markets.businessinsider.com/news/stocks/new-buy-rating-for-beijing-fourth-paradigm-technology-co-ltd-class-h-6682-the-technology-giant-1035564722\n",
            "\n",
            "2. US jury says Apple must pay Masimo $634 million in smartwatch patent case\n",
            "   A federal jury in California said on Friday that Apple owes medical-monitoring technology company Masimo $634 million for infringing a patent covering blood-oxygen reading technology.\n",
            "   Read more: https://www.reuters.com/business/us-jury-says-apple-must-pay-masimo-634-million-smartwatch-patent-case-2025-11-15/\n",
            "\n",
            "3. This smartwatch can monitor your blood pressure, but it's not for everyone - here's why\n",
            "   Wrist-based blood pressure monitoring is a developing technology, but the YHE BP Doctor Med is a product that could help some people.\n",
            "   Read more: https://www.zdnet.com/article/this-smartwatch-can-monitor-your-blood-pressure-but-its-not-for-everyone-heres-why/\n",
            "\n",
            "4. New Buy Rating for Xiaomi (XIACF), the Technology Giant\n",
            "   Bernstein analyst Eunice Lee maintained a Buy rating on Xiaomi on November 12 and set a price target of HK$57.00. The company’s shares closed ye...\n",
            "   Read more: https://markets.businessinsider.com/news/stocks/new-buy-rating-for-xiaomi-xiacf-the-technology-giant-1035564587\n",
            "\n",
            "5. Evolving Skies: Anti-drone technology used on Ukrainian battlefields, in NATO airspace after flyovers\n",
            "   AALBORG, Denmark — In a warehouse more than 900 miles from Ukraine’s capital, workers in northern Denmark painstakingly piece together anti-drone devices. Some of the devices will be exported to Kyiv in the hopes of jamming Russian technology on the battlefield, while others will be shipped across Europe in efforts to combat mysterious drone intrusions […]\n",
            "   Read more: https://www.altoonamirror.com/news/international-news-apwire/2025/11/denmark-ukraine-anti-drone-tech-battlefields-flyovers/\n",
            "\n",
            "\n",
            "User: What are the latest updates on space exploration?\n",
            "Chatbot: 1. What Does 'NASA' Stand For?\n",
            "   NASA has been the leader of our air and space exploration for decades, but what does the name stand for and where did it come from? Here's what we know.\n",
            "   Read more: https://www.bgr.com/2019863/what-nasa-name-means-stand-for-explained/\n",
            "\n",
            "2. 5 Of The Most Expensive NASA Space Missions In History\n",
            "   Space exploration has changed how we look at the universe, but it's costly, and some of the most iconic NASA missions are also among the most expensive.\n",
            "   Read more: https://www.bgr.com/2019315/most-expensive-nasa-space-missions-ever/\n",
            "\n",
            "3. The Future of Design: How CAD Software Is Shaping the Next Wave of Innovation\n",
            "   When we think of the most important innovations of the recent decades, in architecture, engineering, and space exploration, we can’t ignore the innovation that made it all possible - CAD Software. Once a niche solution for blueprints and 2D technical drawings, Computer-Aided Design (CAD) has been evolving into a much larger digital environment that changes\n",
            "   Read more: https://techstartups.com/2025/11/13/the-future-of-design-how-cad-software-is-shaping-the-next-wave-of-innovation/\n",
            "\n",
            "4. Intuitive Machines sees Lanteris deal creating new opportunities in defense and exploration\n",
            "   Intuitive Machines says its acquisition of satellite manufacturer Lanteris Space Systems will open new opportunities for the company.\n",
            "   Read more: https://spacenews.com/intuitive-machines-sees-lanteris-deal-creating-new-opportunities-in-defense-and-exploration/\n",
            "\n",
            "5. LOST IN ORBIT: Chinese Astronauts Stranded in Tiangong Space Station After Debris Strikes Their Return Capsule\n",
            "   This is a distressing trend in space exploration.\n",
            "   Read more: https://www.thegatewaypundit.com/2025/11/lost-orbit-chinese-astronauts-stranded-tiangong-space-station/\n",
            "\n",
            "\n",
            "User: news on current events\n",
            "Chatbot: 1. After blowout loss to Rockets, Blazers hold players-only meeting: ‘We can play way better’\n",
            "   \"We’re like family here. And families have to say what’s on their mind.”\n",
            "   Read more: https://www.oregonlive.com/blazers/2025/11/after-blowout-loss-to-rockets-blazers-hold-players-only-meeting-we-can-play-way-better.html\n",
            "\n",
            "2. Cybercriminals are preparing for Black Friday with new AI-powered scams and attacks - how to shop safely this year\n",
            "   As more people use AI to shop, cybercriminals are using these same AI tools to create scams and phishing attacks to prey on them.\n",
            "   Read more: https://www.tomsguide.com/computing/online-security/cybercriminals-are-preparing-for-black-friday-with-new-ai-powered-scams-and-attacks-how-to-shop-safely-this-year\n",
            "\n",
            "3. Highlights from the quarterfinals of the MIAA football tournament\n",
            "   With the exception of Cathedral vs. Lee in Division 8, which will be played at 4:30 p.m. Saturday, the other 31 football semifinalists are cemented on a night that saw eye-popping offensive stats produced with regularity.\n",
            "   Read more: https://www.bostonglobe.com/2025/11/15/sports/miaa-high-school-football-quarterfinal-highlights/\n",
            "\n",
            "4. UCLA Announces Nico Iamaleava Development Before Ohio State Game\n",
            "   The UCLA Bruins received an injury update on quarterback Nico Iamaleava the night before the game against Ohio State.\n",
            "   Read more: https://athlonsports.com/college-football/ucla-nico-iamaleava-injury-status-ohio-state-game-surfaces\n",
            "\n",
            "5. What’s Next For Joseph Parker After Failed VADA Test?\n",
            "   Former WBO Heavyweight world champion Joseph Parker tested positive for cocaine on the day of his Fabio Wardley fight, as he will likely face disciplinary action.  Reports indicate that Parker’s failed Voluntary Anti-Doping Agency (VADA) test on October 25 showed that cocaine was in his system.\n",
            "   Read more: https://www.yardbarker.com/boxing/articles/whats_next_for_joseph_parker_after_failed_vada_test/s1_17349_43070770\n",
            "\n",
            "\n",
            "User: breaking news in politics\n",
            "Chatbot: 1. The Reuters Institute developed a typology of news influencers.\n",
            "   The survey offers a fascinating look at the modern landscape of news creators and influencers. It offers a taxonomy of news creators, breaking them down into four types of content: commentary, news/investigation, explanation, and specialism. Unsurprisingly, it also found that younger generations have shifted away from traditional media, towards creators and personalities, and that partisan content often outflanks more balanced approaches.\n",
            "[Image: https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/Typology_0.jpg?quality=90&strip=all]\n",
            "[Link: Mapping news creators and influencers in social and video networks | https://reutersinstitute.politics.ox.ac.uk/news-creators-influencers/2025/mapping-news-creators-and-influencers-social-and-video-networks#five | Reuters Institute for the Study of Journalism]\n",
            "   Read more: https://www.theverge.com/news/812078/the-reuters-institute-developed-a-typology-of-news-influencers\n",
            "\n",
            "2. Emma Stone Brags About Not Breaking Bones for Film 'Bugonia'\n",
            "   US News is a recognized leader in college, grad school, hospital, mutual fund, and car rankings. Track elected officials, research health conditions, and find news you can use in politics, business, health, and education.\n",
            "   Read more: https://www.usnews.com/news/top-news/articles/2025-10-22/emma-stone-brags-about-not-breaking-bones-for-film-bugonia\n",
            "\n",
            "\n",
            "User: what's happening in the economy?\n",
            "Chatbot: 1. Lee Zeldin to Newsmax: Trump's EPA Protects Environment, Economy\n",
            "   Zeldin told Finnerty that the Trump EPA is moving faster on deregulation than “entire federal governments in the past.”\n",
            "   Read more: https://www.newsmax.com/politics/lee-zeldin-newsmax-trump-epa/2025/11/14/id/1234662/\n",
            "\n",
            "2. Zeldin to Newsmax: Trump's EPA Protects Environment, Economy\n",
            "   Zeldin told Finnerty that the Trump EPA is moving faster on deregulation than “entire federal governments in the past.”\n",
            "   Read more: https://www.newsmax.com/newsmax-tv/lee-zeldin-newsmax-trump-epa/2025/11/14/id/1234662/\n",
            "\n",
            "3. Trump scraps tariffs on certain items in effort to lower grocery prices\n",
            "   Trump had focused on tariffs to boost domestic production and the economy. but the recent elections showed economic concerns as a top issue, with Democrats gaining wins.\n",
            "   Read more: https://www.pennlive.com/politics/2025/11/trump-scraps-tariffs-on-certain-items-in-effort-to-lower-grocery-prices.html\n",
            "\n",
            "4. Trump announces tariff cuts on food, citing high prices\n",
            "   “The Trump administration is desperately searching around for a solution to their political situation and they found one that is a truly brilliant idea,\" says Chris Hayes. \"‘How about we remove some of the tariffs on goods people buy that are driving prices up?’ Now, if only they could find the clown that imposed those tariffs in the first place.” Rep. Brendan Boyle responds to the news, adding, “the brilliance will take your breath away. Congratulations President Trump for putting out part of the fire that you yourself started about six months ago, but already, damage has been done to our economy.”\n",
            "   Read more: https://www.msnbc.com/all-in/watch/trump-announces-tariff-cuts-on-food-citing-high-prices-252104261690\n",
            "\n",
            "5. Planet Money : NPR\n",
            "   Last month, during the longest government shutdown in U.S. history, Treasury Secretary Scott Bessent announced that the United States had offered to functionally loan Argentina $20 billion. Despite the sums involved, this bailout required no authorization from Congress, because of the loan’s source: an obscure pool of money called the Exchange Stabilization Fund. The ESF is essentially the Treasury Department’s private slush fund. Its history goes all the way back to the Great Depression. But, in the 90 years since its creation, it has only been used one time at this scale to bailout an emerging economy: Mexico, in 1995. That case study contains some helpful lessons that can be used to make sense of Bessent’s recent move. Will this new credit line to Argentina work out as well as it did the last time we tried it? Or will Argentina’s economic troubles hamstring the Exchange Stabilization Fund forever?Pre-order the Planet Money book and get a free gift. /  Subscribe to Planet Money+Listen free: Apple Podcasts, Spotify, the NPR app or anywhere you get podcasts.Facebook / Instagram / TikTok / Our weekly Newsletter.This episode was hosted by Keith Romer and Erika Beras. It was produced by Luis Gallo. It was edited by Eric Mennel and fact checked by Sierra Juarez. It was engineered by Cena Loffredo. Alex Goldmark is Planet Money’s executive producer.\n",
            "   Read more: https://www.npr.org/2025/11/14/nx-s1-5609382/argentina-loan-bessent-treasury-bailout\n",
            "\n",
            "\n",
            "User: today's headlines\n",
            "Chatbot: 1. Full Menus for 2025 Festival of the Holidays In Todays Daily Recap For 11/4/25\n",
            "   Full Menus for 2025 Festival of the Holidays In Todays Daily Recap For 11/4/25\n",
            "   Read more: https://wdwnt.com/2025/11/full-menus-for-2025-festival-of-the-holidays-daily-recap-11-4-25/\n",
            "\n",
            "2. Pure Hedge - Livestock and Grain\n",
            "   Grains About to Trade Higher - Cattle Markets Could be in Trouble + TODAYS FEEDER CATTLE TRADES + YESTERDAYS LIVE CATTLE TRADES\n",
            "   Read more: https://www.barchart.com/story/news/35900035/pure-hedge-livestock-and-grain\n",
            "\n",
            "3. Pure Hedge - Livestock and Grain\n",
            "   Grains About to Trade Higher - Cattle Markets Could be in Trouble + TODAYS FEEDER CATTLE TRADES + YESTERDAYS LIVE CATTLE TRADES\n",
            "   Read more: https://www.barchart.com/story/news/35900034/pure-hedge-livestock-and-grain\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "161865b2"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `langgraph` library was successfully installed and the `GraphState` TypedDict was defined with `user_input`, `intent`, and `response` keys for managing workflow state.\n",
        "*   Functional nodes for intent recognition, general query handling, and news request processing were successfully created and integrated into the `langgraph` workflow.\n",
        "*   A `StateGraph` was constructed with conditional routing based on recognized intent, directing flow to either a \"general\\_query\\_handler\" or \"news\\_request\\_handler\" node, and the graph was successfully compiled.\n",
        "*   An initial attempt to integrate `langgraph` into the `chatbot_response` function using `app.stream()` was unsuccessful, failing to extract the final response and yielding generic error messages across all test cases.\n",
        "*   Refactoring the `chatbot_response` to use `app.invoke()` resolved the issue, enabling correct extraction of the final response from the `langgraph` workflow.\n",
        "*   Post-correction testing confirmed that general queries received appropriate answers and news requests successfully triggered the dedicated news handler, preserving the original `time.sleep` delay, thus validating the refactored chatbot's functionality.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   When integrating `langgraph` or similar state-machine libraries, carefully select the appropriate execution method (`stream()` vs. `invoke()`) based on whether you need intermediate state updates or just the final result.\n",
        "*   Thorough end-to-end testing is crucial after significant refactoring, especially when changing the underlying architecture, to ensure all original functionalities are maintained and new implementations work as expected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ad45afa"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the nodes are defined, I need to define the conditional routing logic using `langgraph` to connect these nodes. This involves importing `StateGraph`, creating a graph, adding the nodes, setting the entry point, defining the conditional edges based on the intent, and compiling the graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79221ae5"
      },
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "def route_intent(state: GraphState):\n",
        "    \"\"\"\n",
        "    Conditional edge based on intent.\n",
        "    \"\"\"\n",
        "    if state[\"intent\"] == \"general_query\":\n",
        "        return \"general_query_handler\"\n",
        "    elif state[\"intent\"] == \"news_request\":\n",
        "        return \"news_request_handler\"\n",
        "    else:\n",
        "        return \"general_query_handler\" # Fallback if intent is not recognized or an unexpected value\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"intent_recognizer\", intent_recognition_node)\n",
        "workflow.add_node(\"general_query_handler\", general_query_node)\n",
        "workflow.add_node(\"news_request_handler\", news_request_node)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"intent_recognizer\")\n",
        "\n",
        "# Add conditional edges from the intent recognizer\n",
        "workflow.add_conditional_edges(\n",
        "    \"intent_recognizer\",\n",
        "    route_intent,\n",
        "    {\n",
        "        \"general_query_handler\": \"general_query_handler\",\n",
        "        \"news_request_handler\": \"news_request_handler\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Set end points for the handlers\n",
        "workflow.add_edge(\"general_query_handler\", END)\n",
        "workflow.add_edge(\"news_request_handler\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"LangGraph workflow compiled successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83b9de38"
      },
      "source": [
        "# Task\n",
        "Create a Streamlit UI for the chatbot by first creating a new Python file `app.py`. Inside `app.py`, consolidate all existing chatbot logic, including:\n",
        "- imports (`nltk`, `re`, `requests`, `os`, `time`, `TavilyClient`, `userdata`, `TypedDict`, `StateGraph`, `END`)\n",
        "- NLTK downloads\n",
        "- API key initialization (for GNEWS_API_KEY and TAVILY_API_KEY)\n",
        "- `preprocess_text` function\n",
        "- `recognize_intent` function\n",
        "- `fetch_news` function\n",
        "- `handle_news_request` function\n",
        "- `fetch_web_results` function\n",
        "- `handle_general_query` function\n",
        "- `GraphState` definition\n",
        "- LangGraph node functions (`intent_recognition_node`, `general_query_node`, `news_request_node`)\n",
        "- LangGraph workflow setup and compilation (`workflow`, `route_intent`, `app`)\n",
        "- The `chatbot_response` function (using `app.invoke`)\n",
        "\n",
        "Also, include necessary `streamlit` imports (`import streamlit as st`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2fcbbff"
      },
      "source": [
        "## Create Streamlit UI File\n",
        "\n",
        "### Subtask:\n",
        "Create a new Python file named `app.py`. This will serve as the container for all chatbot logic and the Streamlit interface.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46dc533e"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires creating a new Python file named `app.py` and consolidating all the chatbot logic into it. I will use the `%%writefile` magic command within a code block to create this file and populate it with all the specified imports, NLTK downloads, API key setups, and function definitions, ensuring to add the `streamlit as st` import.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5edda9c3",
        "outputId": "c8166133-f3dc-44fb-a31a-4c89e9b326ef"
      },
      "source": [
        "%%writefile app.py\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "from google.colab import userdata # Keep for local testing if needed, but will be removed for deployment\n",
        "from tavily import TavilyClient\n",
        "import re\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "import streamlit as st\n",
        "\n",
        "# NLTK Downloads\n",
        "# These usually run once, but for a script, they might need a check or be pre-downloaded\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt_tab')\n",
        "# print(\"'punkt' tokenizer data downloaded successfully.\") # Removed print for clean app.py\n",
        "\n",
        "# API Key Initialization\n",
        "# In a deployed Streamlit app, these would typically be loaded from environment variables\n",
        "# or Streamlit secrets, not userdata.get(). For this step, I'll keep userdata.get()\n",
        "# as it reflects the notebook state, but will add comments for deployment.\n",
        "NEWS_API_KEY = userdata.get('GNEWS_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# For NewsAPI: NEWS_API_BASE_URL = \"https://newsapi.org/v2/everything\"\n",
        "# For GNews API: NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "\n",
        "# Initialize the Tavily client with the API key\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tokenizes and normalizes the input text.\n",
        "    Converts to lowercase and removes punctuation (for simplicity).\n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove non-alphabetic tokens\n",
        "    normalized_tokens = [word for word in tokens if word.isalpha()]\n",
        "    return normalized_tokens\n",
        "\n",
        "def recognize_intent(user_input):\n",
        "    \"\"\"\n",
        "    Analyzes user input to classify the intent as either 'general_query' or 'news_request'.\n",
        "    \"\"\"\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    lower_user_input = user_input.lower()\n",
        "\n",
        "    # Define single-word news keywords\n",
        "    news_single_keywords = [\"news\", \"headlines\"]\n",
        "\n",
        "    # Define multi-word news phrases based on the Chatbot Scope and Requirements Definition\n",
        "    # and observations from previous testing\n",
        "    news_phrases_to_match = [\n",
        "        \"latest updates\", \"current events\", \"breaking news\", \"today's news\",\n",
        "        \"recent developments\", \"what's happening\", \"tell me the news\",\n",
        "        \"give me today's headlines\", \"what are the latest stories\",\n",
        "        \"what is happening in the world\"\n",
        "    ]\n",
        "\n",
        "    # Check for single-word keyword matches in processed tokens\n",
        "    for token in processed_input:\n",
        "        if token in news_single_keywords:\n",
        "            return \"news_request\"\n",
        "\n",
        "    # Check for multi-word phrase matches in the original lowercased input\n",
        "    for phrase in news_phrases_to_match:\n",
        "        if phrase in lower_user_input:\n",
        "            return \"news_request\"\n",
        "\n",
        "    return \"general_query\"\n",
        "\n",
        "def fetch_news(query):\n",
        "    \"\"\"\n",
        "    Fetches news articles from a news API based on the query.\n",
        "    \"\"\"\n",
        "    if not NEWS_API_KEY:\n",
        "        return \"News API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    if not NEWS_API_BASE_URL:\n",
        "        return \"News API base URL is not set. Please provide a valid URL.\"\n",
        "\n",
        "    try:\n",
        "        params = {\n",
        "            'q': query,\n",
        "            'lang': 'en',\n",
        "            'country': 'us', # Or other relevant country codes\n",
        "            'max': 5, # Number of articles to fetch\n",
        "            'apikey': NEWS_API_KEY\n",
        "        }\n",
        "        response = requests.get(NEWS_API_BASE_URL, params=params)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors\n",
        "        data = response.json()\n",
        "\n",
        "        articles = data.get('articles', [])\n",
        "        if not articles:\n",
        "            return \"Sorry, I couldn't find any news for that query.\"\n",
        "\n",
        "        news_output = []\n",
        "        for i, article in enumerate(articles):\n",
        "            title = article.get('title', 'No Title')\n",
        "            description = article.get('description', 'No Description')\n",
        "            url = article.get('url', '#')\n",
        "            news_output.append(f\"{i+1}. {title}\\n   {description}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(news_output)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching news: {e}\"\n",
        "    except ValueError as e:\n",
        "        return f\"Error parsing API response: {e}\"\n",
        "\n",
        "def handle_news_request(user_input):\n",
        "    \"\"\"\n",
        "    Handles a news-specific request by extracting keywords from the user input\n",
        "    and fetching relevant news articles.\n",
        "    \"\"\"\n",
        "    # Define phrases that indicate a news request but should be removed from the query\n",
        "    news_request_phrases = [\n",
        "        \"tell me the news about\",\n",
        "        \"give me today's headlines about\",\n",
        "        \"what are the latest stories on\",\n",
        "        \"what are the latest updates on\",\n",
        "        \"latest news on\",\n",
        "        \"news about\",\n",
        "        \"headlines about\",\n",
        "        \"current events about\",\n",
        "        \"breaking news about\",\n",
        "        \"today's news on\",\n",
        "        \"recent developments on\",\n",
        "        \"what's happening with\",\n",
        "        \"tell me the news\",\n",
        "        \"give me today's headlines\",\n",
        "        \"what are the latest stories\",\n",
        "        \"what is happening in the world\",\n",
        "        \"news\",\n",
        "        \"headlines\",\n",
        "        \"latest updates\",\n",
        "        \"current events\",\n",
        "        \"breaking news\",\n",
        "        \"today's news\",\n",
        "        \"recent developments\",\n",
        "        \"what's happening\"\n",
        "    ]\n",
        "\n",
        "    query = user_input.lower()\n",
        "\n",
        "    # Remove news request phrases from the query\n",
        "    for phrase in news_request_phrases:\n",
        "        if phrase in query:\n",
        "            query = query.replace(phrase, \"\").strip()\n",
        "\n",
        "    # Further clean the query by removing punctuation (except spaces) and extra spaces\n",
        "    query = re.sub(r'[^a-zA-Z0-9\\s]', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "\n",
        "    # If the query becomes empty after removing phrases and cleaning, set a default\n",
        "    if not query:\n",
        "        query = \"top stories\"\n",
        "\n",
        "    return fetch_news(query)\n",
        "\n",
        "def fetch_web_results(query):\n",
        "    \"\"\"\n",
        "    Fetches web search results using the Tavily API.\n",
        "    \"\"\"\n",
        "    if not TAVILY_API_KEY:\n",
        "        return \"Tavily API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    try:\n",
        "        response = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n",
        "\n",
        "        results = response.get('results', [])\n",
        "        if not results:\n",
        "            return \"Sorry, I couldn't find any relevant web results for that query using Tavily.\"\n",
        "\n",
        "        # Synthesize a main answer from the first result's content or a concise summary\n",
        "        synthesized_answer = response.get('answer', 'No summary available.')\n",
        "\n",
        "        web_results_output = []\n",
        "        if synthesized_answer and synthesized_answer != 'No summary available.':\n",
        "            web_results_output.append(f\"Here's what I found: {synthesized_answer}\")\n",
        "        else:\n",
        "            # Fallback to the first result's content if no overall summary is provided\n",
        "            first_result_content = results[0].get('content', 'No content available.')\n",
        "            if first_result_content and len(first_result_content) > 100: # Take a snippet\n",
        "                web_results_output.append(f\"Here's a snippet from a top result: {first_result_content[:200]}...\")\n",
        "            elif first_result_content:\n",
        "                web_results_output.append(f\"Here's what I found: {first_result_content}\")\n",
        "            else:\n",
        "                web_results_output.append(\"Here are some top results:\")\n",
        "\n",
        "        web_results_output.append(\"Top results:\")\n",
        "\n",
        "        for i, item in enumerate(results):\n",
        "            title = item.get('title', 'No Title')\n",
        "            url = item.get('url', '#')\n",
        "            # Tavily 'content' can be long, so we take a snippet for description\n",
        "            content_snippet = item.get('content', 'No description available.')\n",
        "            if len(content_snippet) > 150:\n",
        "                content_snippet = content_snippet[:150] + '...'\n",
        "\n",
        "            web_results_output.append(f\"{i+1}. {title}\\n   {content_snippet}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(web_results_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching web results from Tavily: {e}\"\n",
        "\n",
        "def handle_general_query(user_input):\n",
        "    \"\"\"\n",
        "    Processes a general query and provides a response based on a simple rule-based system,\n",
        "    with a fallback to web search for unknown queries.\n",
        "    \"\"\"\n",
        "    lower_input = user_input.lower()\n",
        "\n",
        "    # Simple keyword-based rule system\n",
        "    if \"what is ai\" in lower_input or \"define ai\" in lower_input:\n",
        "        return \"AI stands for Artificial Intelligence, which is the simulation of human intelligence processes by machines, especially computer systems.\"\n",
        "    elif \"capital of france\" in lower_input:\n",
        "        return \"The capital of France is Paris.\"\n",
        "    elif \"who invented the light bulb\" in lower_input:\n",
        "        return \"Thomas Edison is widely credited with inventing the practical incandescent light bulb.\"\n",
        "    elif \"how to tie a shoelace\" in lower_input:\n",
        "        return \"To tie a shoelace, make two 'bunny ears' with the laces, cross them over, and then tuck one under the other before pulling tight.\"\n",
        "    elif \"your name\" in lower_input or \"who are you\" in lower_input:\n",
        "        return \"I am an AI assistant designed to help with your queries.\"\n",
        "    elif \"hello\" in lower_input or \"hi\" in lower_input:\n",
        "        return \"Hello! How can I assist you today?\"\n",
        "    elif \"how are you\" in lower_input:\n",
        "        return \"I am an AI, so I don't have feelings, but I'm ready to help you!\"\n",
        "    else:\n",
        "        # Fallback to web search if no rule-based answer is found\n",
        "        # print(f\"No direct answer found for '{user_input}'. Attempting web search...\") # Removed print for clean app.py\n",
        "        web_search_result = fetch_web_results(user_input)\n",
        "        if web_search_result:\n",
        "            return web_search_result\n",
        "        else:\n",
        "            return \"I'm not sure how to answer that general query. Could you please rephrase it or ask something else?\"\n",
        "\n",
        "# Graph State Definition\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph. Used to pass information between nodes.\n",
        "    \"\"\"\n",
        "    user_input: str\n",
        "    intent: str\n",
        "    response: str\n",
        "\n",
        "# LangGraph Node Functions\n",
        "def intent_recognition_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to recognize the intent of the user input.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    intent = recognize_intent(user_input)\n",
        "    return {\"intent\": intent}\n",
        "\n",
        "def general_query_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle general queries.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_general_query(user_input)\n",
        "    return {\"response\": response}\n",
        "\n",
        "def news_request_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle news requests.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_news_request(user_input)\n",
        "    time.sleep(2) # Preserve the delay\n",
        "    return {\"response\": response}\n",
        "\n",
        "# LangGraph Workflow Setup and Compilation\n",
        "def route_intent(state: GraphState):\n",
        "    \"\"\"\n",
        "    Conditional edge based on intent.\n",
        "    \"\"\"\n",
        "    if state[\"intent\"] == \"general_query\":\n",
        "        return \"general_query_handler\"\n",
        "    elif state[\"intent\"] == \"news_request\":\n",
        "        return \"news_request_handler\"\n",
        "    else:\n",
        "        return \"general_query_handler\" # Fallback if intent is not recognized or an unexpected value\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"intent_recognizer\", intent_recognition_node)\n",
        "workflow.add_node(\"general_query_handler\", general_query_node)\n",
        "workflow.add_node(\"news_request_handler\", news_request_node)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"intent_recognizer\")\n",
        "\n",
        "# Add conditional edges from the intent recognizer\n",
        "workflow.add_conditional_edges(\n",
        "    \"intent_recognizer\",\n",
        "    route_intent,\n",
        "    {\n",
        "        \"general_query_handler\": \"general_query_handler\",\n",
        "        \"news_request_handler\": \"news_request_handler\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Set end points for the handlers\n",
        "workflow.add_edge(\"general_query_handler\", END)\n",
        "workflow.add_edge(\"news_request_handler\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Chatbot Response Function\n",
        "def chatbot_response(user_input):\n",
        "    \"\"\"\n",
        "    Main function to process user input using the LangGraph workflow.\n",
        "    \"\"\"\n",
        "    initial_state = {\"user_input\": user_input, \"intent\": \"\", \"response\": \"\"}\n",
        "\n",
        "    # Run the graph directly to get the final state\n",
        "    final_state = app.invoke(initial_state)\n",
        "\n",
        "    return final_state.get(\"response\", \"I'm sorry, something went wrong and I couldn't process your request.\")\n",
        "\n",
        "# Streamlit UI (Placeholder for the next steps)\n",
        "# st.title(\"AI Chatbot\")\n",
        "# user_query = st.text_input(\"Ask me anything:\")\n",
        "\n",
        "# if user_query:\n",
        "#     st.write(f\"You: {user_query}\")\n",
        "#     response = chatbot_response(user_query)\n",
        "#     st.write(f\"Chatbot: {response}\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1128cd29"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `app.py` file contains all the backend logic, the next step is to integrate the Streamlit UI components into this file to create an interactive chatbot interface. This involves adding the `st.title`, `st.text_input`, and `st.write` functions to handle user interaction and display responses.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c06604f",
        "outputId": "5e779c8c-928c-4ce2-ad28-7bfb5db09a97"
      },
      "source": [
        "%%writefile app.py\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "from google.colab import userdata # Keep for local testing if needed, but will be removed for deployment\n",
        "from tavily import TavilyClient\n",
        "import re\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "import streamlit as st\n",
        "\n",
        "# NLTK Downloads\n",
        "# These usually run once, but for a script, they might need a check or be pre-downloaded\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt_tab')\n",
        "# print(\"'punkt' tokenizer data downloaded successfully.\") # Removed print for clean app.py\n",
        "\n",
        "# API Key Initialization\n",
        "# In a deployed Streamlit app, these would typically be loaded from environment variables\n",
        "# or Streamlit secrets, not userdata.get(). For this step, I'll keep userdata.get()\n",
        "# as it reflects the notebook state, but will add comments for deployment.\n",
        "NEWS_API_KEY = userdata.get('GNEWS_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# For NewsAPI: NEWS_API_BASE_URL = \"https://newsapi.org/v2/everything\"\n",
        "# For GNews API: NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "\n",
        "# Initialize the Tavily client with the API key\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tokenizes and normalizes the input text.\n",
        "    Converts to lowercase and removes punctuation (for simplicity).\n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove non-alphabetic tokens\n",
        "    normalized_tokens = [word for word in tokens if word.isalpha()]\n",
        "    return normalized_tokens\n",
        "\n",
        "def recognize_intent(user_input):\n",
        "    \"\"\"\n",
        "    Analyzes user input to classify the intent as either 'general_query' or 'news_request'.\n",
        "    \"\"\"\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    lower_user_input = user_input.lower()\n",
        "\n",
        "    # Define single-word news keywords\n",
        "    news_single_keywords = [\"news\", \"headlines\"]\n",
        "\n",
        "    # Define multi-word news phrases based on the Chatbot Scope and Requirements Definition\n",
        "    # and observations from previous testing\n",
        "    news_phrases_to_match = [\n",
        "        \"latest updates\", \"current events\", \"breaking news\", \"today's news\",\n",
        "        \"recent developments\", \"what's happening\", \"tell me the news\",\n",
        "        \"give me today's headlines\", \"what are the latest stories\",\n",
        "        \"what is happening in the world\"\n",
        "    ]\n",
        "\n",
        "    # Check for single-word keyword matches in processed tokens\n",
        "    for token in processed_input:\n",
        "        if token in news_single_keywords:\n",
        "            return \"news_request\"\n",
        "\n",
        "    # Check for multi-word phrase matches in the original lowercased input\n",
        "    for phrase in news_phrases_to_match:\n",
        "        if phrase in lower_user_input:\n",
        "            return \"news_request\"\n",
        "\n",
        "    return \"general_query\"\n",
        "\n",
        "def fetch_news(query):\n",
        "    \"\"\"\n",
        "    Fetches news articles from a news API based on the query.\n",
        "    \"\"\"\n",
        "    if not NEWS_API_KEY:\n",
        "        return \"News API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    if not NEWS_API_BASE_URL:\n",
        "        return \"News API base URL is not set. Please provide a valid URL.\"\n",
        "\n",
        "    try:\n",
        "        params = {\n",
        "            'q': query,\n",
        "            'lang': 'en',\n",
        "            'country': 'us', # Or other relevant country codes\n",
        "            'max': 5, # Number of articles to fetch\n",
        "            'apikey': NEWS_API_KEY\n",
        "        }\n",
        "        response = requests.get(NEWS_API_BASE_URL, params=params)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors\n",
        "        data = response.json()\n",
        "\n",
        "        articles = data.get('articles', [])\n",
        "        if not articles:\n",
        "            return \"Sorry, I couldn't find any news for that query.\"\n",
        "\n",
        "        news_output = []\n",
        "        for i, article in enumerate(articles):\n",
        "            title = article.get('title', 'No Title')\n",
        "            description = article.get('description', 'No Description')\n",
        "            url = article.get('url', '#')\n",
        "            news_output.append(f\"{i+1}. {title}\\n   {description}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(news_output)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching news: {e}\"\n",
        "    except ValueError as e:\n",
        "        return f\"Error parsing API response: {e}\"\n",
        "\n",
        "def handle_news_request(user_input):\n",
        "    \"\"\"\n",
        "    Handles a news-specific request by extracting keywords from the user input\n",
        "    and fetching relevant news articles.\n",
        "    \"\"\"\n",
        "    # Define phrases that indicate a news request but should be removed from the query\n",
        "    news_request_phrases = [\n",
        "        \"tell me the news about\",\n",
        "        \"give me today's headlines about\",\n",
        "        \"what are the latest stories on\",\n",
        "        \"what are the latest updates on\",\n",
        "        \"latest news on\",\n",
        "        \"news about\",\n",
        "        \"headlines about\",\n",
        "        \"current events about\",\n",
        "        \"breaking news about\",\n",
        "        \"today's news on\",\n",
        "        \"recent developments on\",\n",
        "        \"what's happening with\",\n",
        "        \"tell me the news\",\n",
        "        \"give me today's headlines\",\n",
        "        \"what are the latest stories\",\n",
        "        \"what is happening in the world\",\n",
        "        \"news\",\n",
        "        \"headlines\",\n",
        "        \"latest updates\",\n",
        "        \"current events\",\n",
        "        \"breaking news\",\n",
        "        \"today's news\",\n",
        "        \"recent developments\",\n",
        "        \"what's happening\"\n",
        "    ]\n",
        "\n",
        "    query = user_input.lower()\n",
        "\n",
        "    # Remove news request phrases from the query\n",
        "    for phrase in news_request_phrases:\n",
        "        if phrase in query:\n",
        "            query = query.replace(phrase, \"\").strip()\n",
        "\n",
        "    # Further clean the query by removing punctuation (except spaces) and extra spaces\n",
        "    query = re.sub(r'[^a-zA-Z0-9\\s]', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "\n",
        "    # If the query becomes empty after removing phrases and cleaning, set a default\n",
        "    if not query:\n",
        "        query = \"top stories\"\n",
        "\n",
        "    return fetch_news(query)\n",
        "\n",
        "def fetch_web_results(query):\n",
        "    \"\"\"\n",
        "    Fetches web search results using the Tavily API.\n",
        "    \"\"\"\n",
        "    if not TAVILY_API_KEY:\n",
        "        return \"Tavily API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    try:\n",
        "        response = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n",
        "\n",
        "        results = response.get('results', [])\n",
        "        if not results:\n",
        "            return \"Sorry, I couldn't find any relevant web results for that query using Tavily.\"\n",
        "\n",
        "        # Synthesize a main answer from the first result's content or a concise summary\n",
        "        synthesized_answer = response.get('answer', 'No summary available.')\n",
        "\n",
        "        web_results_output = []\n",
        "        if synthesized_answer and synthesized_answer != 'No summary available.':\n",
        "            web_results_output.append(f\"Here's what I found: {synthesized_answer}\")\n",
        "        else:\n",
        "            # Fallback to the first result's content if no overall summary is provided\n",
        "            first_result_content = results[0].get('content', 'No content available.')\n",
        "            if first_result_content and len(first_result_content) > 100: # Take a snippet\n",
        "                web_results_output.append(f\"Here's a snippet from a top result: {first_result_content[:200]}...\")\n",
        "            elif first_result_content:\n",
        "                web_results_output.append(f\"Here's what I found: {first_result_content}\")\n",
        "            else:\n",
        "                web_results_output.append(\"Here are some top results:\")\n",
        "\n",
        "        web_results_output.append(\"Top results:\")\n",
        "\n",
        "        for i, item in enumerate(results):\n",
        "            title = item.get('title', 'No Title')\n",
        "            url = item.get('url', '#')\n",
        "            # Tavily 'content' can be long, so we take a snippet for description\n",
        "            content_snippet = item.get('content', 'No description available.')\n",
        "            if len(content_snippet) > 150:\n",
        "                content_snippet = content_snippet[:150] + '...'\n",
        "\n",
        "            web_results_output.append(f\"{i+1}. {title}\\n   {content_snippet}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(web_results_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching web results from Tavily: {e}\"\n",
        "\n",
        "def handle_general_query(user_input):\n",
        "    \"\"\"\n",
        "    Processes a general query and provides a response based on a simple rule-based system,\n",
        "    with a fallback to web search for unknown queries.\n",
        "    \"\"\"\n",
        "    lower_input = user_input.lower()\n",
        "\n",
        "    # Simple keyword-based rule system\n",
        "    if \"what is ai\" in lower_input or \"define ai\" in lower_input:\n",
        "        return \"AI stands for Artificial Intelligence, which is the simulation of human intelligence processes by machines, especially computer systems.\"\n",
        "    elif \"capital of france\" in lower_input:\n",
        "        return \"The capital of France is Paris.\"\n",
        "    elif \"who invented the light bulb\" in lower_input:\n",
        "        return \"Thomas Edison is widely credited with inventing the practical incandescent light bulb.\"\n",
        "    elif \"how to tie a shoelace\" in lower_input:\n",
        "        return \"To tie a shoelace, make two 'bunny ears' with the laces, cross them over, and then tuck one under the other before pulling tight.\"\n",
        "    elif \"your name\" in lower_input or \"who are you\" in lower_input:\n",
        "        return \"I am an AI assistant designed to help with your queries.\"\n",
        "    elif \"hello\" in lower_input or \"hi\" in lower_input:\n",
        "        return \"Hello! How can I assist you today?\"\n",
        "    elif \"how are you\" in lower_input:\n",
        "        return \"I am an AI, so I don't have feelings, but I'm ready to help you!\"\n",
        "    else:\n",
        "        # Fallback to web search if no rule-based answer is found\n",
        "        # print(f\"No direct answer found for '{user_input}'. Attempting web search...\") # Removed print for clean app.py\n",
        "        web_search_result = fetch_web_results(user_input)\n",
        "        if web_search_result:\n",
        "            return web_search_result\n",
        "        else:\n",
        "            return \"I'm not sure how to answer that general query. Could you please rephrase it or ask something else?\"\n",
        "\n",
        "# Graph State Definition\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph. Used to pass information between nodes.\n",
        "    \"\"\"\n",
        "    user_input: str\n",
        "    intent: str\n",
        "    response: str\n",
        "\n",
        "# LangGraph Node Functions\n",
        "def intent_recognition_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to recognize the intent of the user input.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    intent = recognize_intent(user_input)\n",
        "    return {\"intent\": intent}\n",
        "\n",
        "def general_query_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle general queries.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_general_query(user_input)\n",
        "    return {\"response\": response}\n",
        "\n",
        "def news_request_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle news requests.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_news_request(user_input)\n",
        "    time.sleep(2) # Preserve the delay\n",
        "    return {\"response\": response}\n",
        "\n",
        "# LangGraph Workflow Setup and Compilation\n",
        "def route_intent(state: GraphState):\n",
        "    \"\"\"\n",
        "    Conditional edge based on intent.\n",
        "    \"\"\"\n",
        "    if state[\"intent\"] == \"general_query\":\n",
        "        return \"general_query_handler\"\n",
        "    elif state[\"intent\"] == \"news_request\":\n",
        "        return \"news_request_handler\"\n",
        "    else:\n",
        "        return \"general_query_handler\" # Fallback if intent is not recognized or an unexpected value\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"intent_recognizer\", intent_recognition_node)\n",
        "workflow.add_node(\"general_query_handler\", general_query_node)\n",
        "workflow.add_node(\"news_request_handler\", news_request_node)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"intent_recognizer\")\n",
        "\n",
        "# Add conditional edges from the intent recognizer\n",
        "workflow.add_conditional_edges(\n",
        "    \"intent_recognizer\",\n",
        "    route_intent,\n",
        "    {\n",
        "        \"general_query_handler\": \"general_query_handler\",\n",
        "        \"news_request_handler\": \"news_request_handler\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Set end points for the handlers\n",
        "workflow.add_edge(\"general_query_handler\", END)\n",
        "workflow.add_edge(\"news_request_handler\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Chatbot Response Function\n",
        "def chatbot_response(user_input):\n",
        "    \"\"\"\n",
        "    Main function to process user input using the LangGraph workflow.\n",
        "    \"\"\"\n",
        "    initial_state = {\"user_input\": user_input, \"intent\": \"\", \"response\": \"\"}\n",
        "\n",
        "    # Run the graph directly to get the final state\n",
        "    final_state = app.invoke(initial_state)\n",
        "\n",
        "    return final_state.get(\"response\", \"I'm sorry, something went wrong and I couldn't process your request.\")\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"AI Chatbot\")\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# Accept user input\n",
        "if user_query := st.chat_input(\"Ask me anything:\"):\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    # Display user message in chat message container\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_query)\n",
        "\n",
        "    # Generate and display assistant response\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            response = chatbot_response(user_query)\n",
        "            st.markdown(response)\n",
        "    # Add assistant response to chat history\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c6bc476"
      },
      "source": [
        "## Implement News Category Selection\n",
        "\n",
        "### Subtask:\n",
        "Add a user interface element for selecting news categories and manage the selected category in Streamlit's session state.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1d908a5"
      },
      "source": [
        "**Reasoning**:\n",
        "To implement the news category selection, I will first modify the `app.py` file to include a Streamlit selectbox for categories and manage the selected category in `st.session_state`. Then, I will update the `handle_news_request` function to incorporate this selected category into the news query.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7837f61",
        "outputId": "350d489a-97ab-4d5c-e641-622fbfdbafab"
      },
      "source": [
        "%%writefile app.py\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "from google.colab import userdata # Keep for local testing if needed, but will be removed for deployment\n",
        "from tavily import TavilyClient\n",
        "import re\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "import streamlit as st\n",
        "\n",
        "# NLTK Downloads\n",
        "# These usually run once, but for a script, they might need a check or be pre-downloaded\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt_tab')\n",
        "# print(\"'punkt' tokenizer data downloaded successfully.\") # Removed print for clean app.py\n",
        "\n",
        "# API Key Initialization\n",
        "# In a deployed Streamlit app, these would typically be loaded from environment variables\n",
        "# or Streamlit secrets, not userdata.get(). For this step, I'll keep userdata.get()\n",
        "# as it reflects the notebook state, but will add comments for deployment.\n",
        "NEWS_API_KEY = userdata.get('GNEWS_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# For NewsAPI: NEWS_API_BASE_URL = \"https://newsapi.org/v2/everything\"\n",
        "# For GNews API: NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "NEWS_API_BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "\n",
        "# Initialize the Tavily client with the API key\n",
        "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Tokenizes and normalizes the input text.\n",
        "    Converts to lowercase and removes punctuation (for simplicity).\n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove non-alphabetic tokens\n",
        "    normalized_tokens = [word for word in tokens if word.isalpha()]\n",
        "    return normalized_tokens\n",
        "\n",
        "def recognize_intent(user_input):\n",
        "    \"\"\"\n",
        "    Analyzes user input to classify the intent as either 'general_query' or 'news_request'.\n",
        "    \"\"\"\n",
        "    processed_input = preprocess_text(user_input)\n",
        "    lower_user_input = user_input.lower()\n",
        "\n",
        "    # Define single-word news keywords\n",
        "    news_single_keywords = [\"news\", \"headlines\"]\n",
        "\n",
        "    # Define multi-word news phrases based on the Chatbot Scope and Requirements Definition\n",
        "    # and observations from previous testing\n",
        "    news_phrases_to_match = [\n",
        "        \"latest updates\", \"current events\", \"breaking news\", \"today's news\",\n",
        "        \"recent developments\", \"what's happening\", \"tell me the news\",\n",
        "        \"give me today's headlines\", \"what are the latest stories\",\n",
        "        \"what is happening in the world\"\n",
        "    ]\n",
        "\n",
        "    # Check for single-word keyword matches in processed tokens\n",
        "    for token in processed_input:\n",
        "        if token in news_single_keywords:\n",
        "            return \"news_request\"\n",
        "\n",
        "    # Check for multi-word phrase matches in the original lowercased input\n",
        "    for phrase in news_phrases_to_match:\n",
        "        if phrase in lower_user_input:\n",
        "            return \"news_request\"\n",
        "\n",
        "    return \"general_query\"\n",
        "\n",
        "def fetch_news(query):\n",
        "    \"\"\"\n",
        "    Fetches news articles from a news API based on the query.\n",
        "    \"\"\"\n",
        "    if not NEWS_API_KEY:\n",
        "        return \"News API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    if not NEWS_API_BASE_URL:\n",
        "        return \"News API base URL is not set. Please provide a valid URL.\"\n",
        "\n",
        "    try:\n",
        "        params = {\n",
        "            'q': query,\n",
        "            'lang': 'en',\n",
        "            'country': 'us', # Or other relevant country codes\n",
        "            'max': 5, # Number of articles to fetch\n",
        "            'apikey': NEWS_API_KEY\n",
        "        }\n",
        "        response = requests.get(NEWS_API_BASE_URL, params=params)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors\n",
        "        data = response.json()\n",
        "\n",
        "        articles = data.get('articles', [])\n",
        "        if not articles:\n",
        "            return \"Sorry, I couldn't find any news for that query.\"\n",
        "\n",
        "        news_output = []\n",
        "        for i, article in enumerate(articles):\n",
        "            title = article.get('title', 'No Title')\n",
        "            description = article.get('description', 'No Description')\n",
        "            url = article.get('url', '#')\n",
        "            news_output.append(f\"{i+1}. {title}\\n   {description}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(news_output)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error fetching news: {e}\"\n",
        "    except ValueError as e:\n",
        "        return f\"Error parsing API response: {e}\"\n",
        "\n",
        "def handle_news_request(user_input, category=\"General\"):\n",
        "    \"\"\"\n",
        "    Handles a news-specific request by extracting keywords from the user input\n",
        "    and fetching relevant news articles, optionally filtered by category.\n",
        "    \"\"\"\n",
        "    # Define phrases that indicate a news request but should be removed from the query\n",
        "    news_request_phrases = [\n",
        "        \"tell me the news about\",\n",
        "        \"give me today's headlines about\",\n",
        "        \"what are the latest stories on\",\n",
        "        \"what are the latest updates on\",\n",
        "        \"latest news on\",\n",
        "        \"news about\",\n",
        "        \"headlines about\",\n",
        "        \"current events about\",\n",
        "        \"breaking news about\",\n",
        "        \"today's news on\",\n",
        "        \"recent developments on\",\n",
        "        \"what's happening with\",\n",
        "        \"tell me the news\",\n",
        "        \"give me today's headlines\",\n",
        "        \"what are the latest stories\",\n",
        "        \"what is happening in the world\",\n",
        "        \"news\",\n",
        "        \"headlines\",\n",
        "        \"latest updates\",\n",
        "        \"current events\",\n",
        "        \"breaking news\",\n",
        "        \"today's news\",\n",
        "        \"recent developments\",\n",
        "        \"what's happening\"\n",
        "    ]\n",
        "\n",
        "    query = user_input.lower()\n",
        "\n",
        "    # Remove news request phrases from the query\n",
        "    for phrase in news_request_phrases:\n",
        "        if phrase in query:\n",
        "            query = query.replace(phrase, \"\").strip()\n",
        "\n",
        "    # Further clean the query by removing punctuation (except spaces) and extra spaces\n",
        "    query = re.sub(r'[^a-zA-Z0-9\\s]', '', query)\n",
        "    query = re.sub(r'\\s+', ' ', query).strip()\n",
        "\n",
        "    # Append category to query if it's not 'General' and query is not empty\n",
        "    if category != \"General\" and category.strip() != \"\":\n",
        "        if query:\n",
        "            query = f\"{query} {category}\"\n",
        "        else:\n",
        "            query = category # If only category was selected and no specific query\n",
        "\n",
        "    # If the query becomes empty after removing phrases and cleaning, set a default\n",
        "    if not query:\n",
        "        query = \"top stories\"\n",
        "\n",
        "    return fetch_news(query)\n",
        "\n",
        "def fetch_web_results(query):\n",
        "    \"\"\"\n",
        "    Fetches web search results using the Tavily API.\n",
        "    \"\"\"\n",
        "    if not TAVILY_API_KEY:\n",
        "        return \"Tavily API key is not set. Please provide a valid API key.\"\n",
        "\n",
        "    try:\n",
        "        response = tavily_client.search(query=query, search_depth=\"advanced\", max_results=5)\n",
        "\n",
        "        results = response.get('results', [])\n",
        "        if not results:\n",
        "            return \"Sorry, I couldn't find any relevant web results for that query using Tavily.\"\n",
        "\n",
        "        # Synthesize a main answer from the first result's content or a concise summary\n",
        "        synthesized_answer = response.get('answer', 'No summary available.')\n",
        "\n",
        "        web_results_output = []\n",
        "        if synthesized_answer and synthesized_answer != 'No summary available.':\n",
        "            web_results_output.append(f\"Here's what I found: {synthesized_answer}\")\n",
        "        else:\n",
        "            # Fallback to the first result's content if no overall summary is provided\n",
        "            first_result_content = results[0].get('content', 'No content available.')\n",
        "            if first_result_content and len(first_result_content) > 100: # Take a snippet\n",
        "                web_results_output.append(f\"Here's a snippet from a top result: {first_result_content[:200]}...\")\n",
        "            elif first_result_content:\n",
        "                web_results_output.append(f\"Here's what I found: {first_result_content}\")\n",
        "            else:\n",
        "                web_results_output.append(\"Here are some top results:\")\n",
        "\n",
        "        web_results_output.append(\"Top results:\")\n",
        "\n",
        "        for i, item in enumerate(results):\n",
        "            title = item.get('title', 'No Title')\n",
        "            url = item.get('url', '#')\n",
        "            # Tavily 'content' can be long, so we take a snippet for description\n",
        "            content_snippet = item.get('content', 'No description available.')\n",
        "            if len(content_snippet) > 150:\n",
        "                content_snippet = content_snippet[:150] + '...'\n",
        "\n",
        "            web_results_output.append(f\"{i+1}. {title}\\n   {content_snippet}\\n   Read more: {url}\\n\")\n",
        "\n",
        "        return \"\\n\".join(web_results_output)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching web results from Tavily: {e}\"\n",
        "\n",
        "def handle_general_query(user_input):\n",
        "    \"\"\"\n",
        "    Processes a general query and provides a response based on a simple rule-based system,\n",
        "    with a fallback to web search for unknown queries.\n",
        "    \"\"\"\n",
        "    lower_input = user_input.lower()\n",
        "\n",
        "    # Simple keyword-based rule system\n",
        "    if \"what is ai\" in lower_input or \"define ai\" in lower_input:\n",
        "        return \"AI stands for Artificial Intelligence, which is the simulation of human intelligence processes by machines, especially computer systems.\"\n",
        "    elif \"capital of france\" in lower_input:\n",
        "        return \"The capital of France is Paris.\"\n",
        "    elif \"who invented the light bulb\" in lower_input:\n",
        "        return \"Thomas Edison is widely credited with inventing the practical incandescent light bulb.\"\n",
        "    elif \"how to tie a shoelace\" in lower_input:\n",
        "        return \"To tie a shoelace, make two 'bunny ears' with the laces, cross them over, and then tuck one under the other before pulling tight.\"\n",
        "    elif \"your name\" in lower_input or \"who are you\" in lower_input:\n",
        "        return \"I am an AI assistant designed to help with your queries.\"\n",
        "    elif \"hello\" in lower_input or \"hi\" in lower_input:\n",
        "        return \"Hello! How can I assist you today?\"\n",
        "    elif \"how are you\" in lower_input:\n",
        "        return \"I am an AI, so I don't have feelings, but I'm ready to help you!\"\n",
        "    else:\n",
        "        # Fallback to web search if no rule-based answer is found\n",
        "        # print(f\"No direct answer found for '{user_input}'. Attempting web search...\") # Removed print for clean app.py\n",
        "        web_search_result = fetch_web_results(user_input)\n",
        "        if web_search_result:\n",
        "            return web_search_result\n",
        "        else:\n",
        "            return \"I'm not sure how to answer that general query. Could you please rephrase it or ask something else?\"\n",
        "\n",
        "# Graph State Definition\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph. Used to pass information between nodes.\n",
        "    \"\"\"\n",
        "    user_input: str\n",
        "    intent: str\n",
        "    response: str\n",
        "    news_category: str # Added for news category selection\n",
        "\n",
        "# LangGraph Node Functions\n",
        "def intent_recognition_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to recognize the intent of the user input.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    intent = recognize_intent(user_input)\n",
        "    return {\"intent\": intent}\n",
        "\n",
        "def general_query_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle general queries.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    response = handle_general_query(user_input)\n",
        "    return {\"response\": response}\n",
        "\n",
        "def news_request_node(state: GraphState) -> GraphState:\n",
        "    \"\"\"\n",
        "    Node to handle news requests.\n",
        "    \"\"\"\n",
        "    user_input = state[\"user_input\"]\n",
        "    # Pass the selected news category to handle_news_request\n",
        "    selected_news_category = state.get(\"news_category\", \"General\")\n",
        "    response = handle_news_request(user_input, selected_news_category)\n",
        "    time.sleep(2) # Preserve the delay\n",
        "    return {\"response\": response}\n",
        "\n",
        "# LangGraph Workflow Setup and Compilation\n",
        "def route_intent(state: GraphState):\n",
        "    \"\"\"\n",
        "    Conditional edge based on intent.\n",
        "    \"\"\"\n",
        "    if state[\"intent\"] == \"general_query\":\n",
        "        return \"general_query_handler\"\n",
        "    elif state[\"intent\"] == \"news_request\":\n",
        "        return \"news_request_handler\"\n",
        "    else:\n",
        "        return \"general_query_handler\" # Fallback if intent is not recognized or an unexpected value\n",
        "\n",
        "# Build the graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"intent_recognizer\", intent_recognition_node)\n",
        "workflow.add_node(\"general_query_handler\", general_query_node)\n",
        "workflow.add_node(\"news_request_handler\", news_request_node)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"intent_recognizer\")\n",
        "\n",
        "# Add conditional edges from the intent recognizer\n",
        "workflow.add_conditional_edges(\n",
        "    \"intent_recognizer\",\n",
        "    route_intent,\n",
        "    {\n",
        "        \"general_query_handler\": \"general_query_handler\",\n",
        "        \"news_request_handler\": \"news_request_handler\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Set end points for the handlers\n",
        "workflow.add_edge(\"general_query_handler\", END)\n",
        "workflow.add_edge(\"news_request_handler\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Chatbot Response Function\n",
        "def chatbot_response(user_input, news_category=\"General\"):\n",
        "    \"\"\"\n",
        "    Main function to process user input using the LangGraph workflow.\n",
        "    \"\"\"\n",
        "    initial_state = {\"user_input\": user_input, \"intent\": \"\", \"response\": \"\", \"news_category\": news_category}\n",
        "\n",
        "    # Run the graph directly to get the final state\n",
        "    final_state = app.invoke(initial_state)\n",
        "\n",
        "    return final_state.get(\"response\", \"I'm sorry, something went wrong and I couldn't process your request.\")\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"AI Chatbot\")\n",
        "\n",
        "# News Category Selection\n",
        "news_categories = ['General', 'Technology', 'Politics', 'Sports', 'Business', 'Health', 'Science']\n",
        "if 'selected_news_category' not in st.session_state:\n",
        "    st.session_state.selected_news_category = 'General'\n",
        "\n",
        "st.session_state.selected_news_category = st.selectbox(\n",
        "    \"Select News Category:\",\n",
        "    news_categories,\n",
        "    index=news_categories.index(st.session_state.selected_news_category),\n",
        "    key=\"news_category_selector\"\n",
        ")\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# Accept user input\n",
        "if user_query := st.chat_input(\"Ask me anything:\"):\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    # Display user message in chat message container\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_query)\n",
        "\n",
        "    # Generate and display assistant response, passing the selected news category\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            response = chatbot_response(user_query, st.session_state.selected_news_category)\n",
        "            st.markdown(response)\n",
        "    # Add assistant response to chat history\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1199a5f6"
      },
      "source": [
        "## Provide Run Instructions\n",
        "\n",
        "### Subtask:\n",
        "Give clear instructions on how to execute the Streamlit application from the Colab environment, including necessary commands for running the app and creating a public URL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0792830f"
      },
      "source": [
        "### Instructions\n",
        "1. Run the `app.py` file using Streamlit, specifying the port 8501. Use the following command in a new code cell:\n",
        "```bash\n",
        "!streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false\n",
        "```\n",
        "2. While the Streamlit app is running, use `npx localtunnel` in **another new code cell** to expose the Streamlit application to the internet, creating a public URL. This command will output a URL that you can click to access your Streamlit app:\n",
        "```bash\n",
        "!npx localtunnel --port 8501\n",
        "```\n",
        "**Important:** Keep both cells running to maintain the Streamlit app and its public URL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f0978f8"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the features of the new Streamlit interface.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51acba98"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**Summarize the features of the new Streamlit interface:**\n",
        "The new Streamlit interface for the chatbot includes:\n",
        "*   A user-friendly chat interface where users can input queries.\n",
        "*   Display of chat history, showing both user inputs and chatbot responses.\n",
        "*   A loading spinner to indicate when the chatbot is processing a query.\n",
        "*   A dropdown menu for selecting news categories, allowing users to filter news requests by 'General', 'Technology', 'Politics', 'Sports', 'Business', 'Health', and 'Science'.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The entire chatbot logic, including NLTK downloads, API key initialization, `preprocess_text`, `recognize_intent`, `fetch_news`, `handle_news_request`, `fetch_web_results`, `handle_general_query` functions, `GraphState` definition, LangGraph nodes, workflow setup, compilation, and `chatbot_response` function, was successfully consolidated into a single `app.py` file.\n",
        "*   The `app.py` file was equipped with a basic Streamlit UI, featuring a title, chat history management (`st.session_state`), a `st.chat_input` for user interaction, and `st.chat_message` for displaying responses, along with a `st.spinner` for indicating processing.\n",
        "*   A `st.selectbox` UI element was added to allow users to select a news category from a predefined list (e.g., 'General', 'Technology', 'Politics'). This selection is maintained using `st.session_state.selected_news_category`.\n",
        "*   The LangGraph's `GraphState` was extended to include `news_category`, and the `news_request_node` was modified to pass the user-selected category to the `handle_news_request` function.\n",
        "*   The `handle_news_request` function was enhanced to incorporate the selected news category into the news query, allowing for category-specific news retrieval.\n",
        "*   Clear instructions were provided for running the Streamlit application within a Colab environment using `!streamlit run app.py` and for generating a public URL using `!npx localtunnel --port 8501`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Enhance API Key Management**: For production deployment, transition from `userdata.get()` to Streamlit secrets or environment variables for API key management to improve security and deployment flexibility.\n",
        "*   **Expand News Categories & Filtering**: Consider integrating more sophisticated news category recognition from user input directly, rather than relying solely on a dropdown, or allow for multiple category selections.\n"
      ]
    }
  ]
}